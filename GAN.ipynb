{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/K99MmJb2vy/r0B8ZIj6J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysj9909/GANs/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generative Adverasarial Network**\n",
        "\n",
        " * paper link: https://arxiv.org/pdf/1406.2661.pdf\n",
        " * code reference : https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py\n",
        " * my paper review : https://blog.naver.com/wsz87/222572167729"
      ],
      "metadata": {
        "id": "UW9a3NZGiWWR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ytCsV9miJPl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torchvision.utils import save_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "num_epochs = 200\n",
        "batch_size = 128\n",
        "learning_rate = 0.0002\n",
        "latent_dim = 100\n",
        "img_size = 28   # MNIST dataset"
      ],
      "metadata": {
        "id": "cVFYgkQnkkrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.MNIST(root = \"./data\", train = True, download = True,\n",
        "                                           transform = transforms.Compose([transforms.Resize(img_size),\n",
        "                                                                           transforms.ToTensor(), \n",
        "                                                                           transforms.Normalize([0.5], [0.5])]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True, num_workers = 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfdY3kXgjx-_",
        "outputId": "8bb2c998-c615-4bde-d68d-49440ffbcc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    def Block(in_feat, out_feat, normalize = True):\n",
        "      layers = [nn.Linear(in_feat, out_feat)]\n",
        "      if normalize : \n",
        "        layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "      layers.append(nn.LeakyReLU(0.2, inplace = True))\n",
        "      return layers\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "        *Block(latent_dim, 128, normalize = False),\n",
        "        *Block(128, 256),\n",
        "        *Block(256, 512),\n",
        "        *Block(512, 1024),\n",
        "        nn.Linear(1024, img_size **2),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, z):\n",
        "    img = self.model(z)\n",
        "    img = img.view(img.size(0), 1, img_size, img_size)      # (batch_size, 1, 28, 28)\n",
        "    return img"
      ],
      "metadata": {
        "id": "vAvaersiloNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(img_size * img_size, 512),\n",
        "        nn.LeakyReLU(0.2, inplace = True),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.LeakyReLU(0.2, inplace = True),\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "  \n",
        "  def forward(self, img):\n",
        "    img = img.view(img.size(0), -1)\n",
        "    output = self.model(img)\n",
        "    return output\n",
        "    "
      ],
      "metadata": {
        "id": "zxmGKs2t8E-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "generator.cuda()\n",
        "discriminator.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4xVaPK3AFWr",
        "outputId": "34c4ddd2-1806-42ae-9a34-17717bc810ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
              "    (5): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and optimizers\n",
        "adversarial_loss = nn.BCELoss()\n",
        "adversarial_loss.cuda()\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr = learning_rate, betas = (0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr = learning_rate, betas = (0.5, 0.999))"
      ],
      "metadata": {
        "id": "jQMgbNgX_58i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "sample_interval = 2000 \n",
        "for epoch in range(num_epochs):\n",
        "  for i, (imgs, _) in enumerate(train_loader):\n",
        "    real_imgs = imgs.cuda()\n",
        "\n",
        "    z = torch.normal(mean = 0, std = 1, size = (imgs.shape[0], latent_dim)).cuda()\n",
        "    fake_imgs = generator(z)\n",
        "    \n",
        "    # generate labels for real and fake\n",
        "    real = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(1.0)\n",
        "    fake = torch.cuda.FloatTensor(imgs.size(0), 1).fill_(0.0)\n",
        "\n",
        "    # Train Generator\n",
        "    optimizer_G.zero_grad()\n",
        "    G_loss = adversarial_loss(discriminator(fake_imgs), real)\n",
        "    G_loss.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "    # Train Discriminator\n",
        "    optimizer_D.zero_grad()\n",
        "    D_loss = adversarial_loss(discriminator(real_imgs), real) + adversarial_loss(discriminator(fake_imgs.detach()), fake)\n",
        "    D_loss.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    done = epoch * len(train_loader) + i\n",
        "    if done % sample_interval == 0:\n",
        "      save_image(fake_imgs[:25], f\"{done}.png\", nrow = 5, normalize = True)\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "      print(f\"Epoch [{epoch + 1} / {num_epochs}], Step [{i + 1} / {len(train_loader)}], Generator Loss : {G_loss.item()}, Discriminator Loss : {D_loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljD-8UeHAghk",
        "outputId": "3db4d9a1-afb1-4437-b2b3-47fe9d8d94c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 200], Step [100 / 469], Generator Loss : 2.09584903717041, Discriminator Loss : 0.3406221270561218\n",
            "Epoch [1 / 200], Step [200 / 469], Generator Loss : 2.4983391761779785, Discriminator Loss : 0.5619372725486755\n",
            "Epoch [1 / 200], Step [300 / 469], Generator Loss : 1.9805865287780762, Discriminator Loss : 0.40672174096107483\n",
            "Epoch [1 / 200], Step [400 / 469], Generator Loss : 2.2893991470336914, Discriminator Loss : 0.44277501106262207\n",
            "Epoch [2 / 200], Step [100 / 469], Generator Loss : 1.2466927766799927, Discriminator Loss : 0.6105299592018127\n",
            "Epoch [2 / 200], Step [200 / 469], Generator Loss : 2.3442912101745605, Discriminator Loss : 0.3991682827472687\n",
            "Epoch [2 / 200], Step [300 / 469], Generator Loss : 5.255550384521484, Discriminator Loss : 1.7649363279342651\n",
            "Epoch [2 / 200], Step [400 / 469], Generator Loss : 2.0819334983825684, Discriminator Loss : 0.43060141801834106\n",
            "Epoch [3 / 200], Step [100 / 469], Generator Loss : 2.6495425701141357, Discriminator Loss : 0.49267396330833435\n",
            "Epoch [3 / 200], Step [200 / 469], Generator Loss : 1.515131950378418, Discriminator Loss : 0.4582310914993286\n",
            "Epoch [3 / 200], Step [300 / 469], Generator Loss : 1.684560775756836, Discriminator Loss : 0.3876866400241852\n",
            "Epoch [3 / 200], Step [400 / 469], Generator Loss : 1.8096122741699219, Discriminator Loss : 0.6021759510040283\n",
            "Epoch [4 / 200], Step [100 / 469], Generator Loss : 2.668578863143921, Discriminator Loss : 0.44228655099868774\n",
            "Epoch [4 / 200], Step [200 / 469], Generator Loss : 1.1863130331039429, Discriminator Loss : 0.6128188967704773\n",
            "Epoch [4 / 200], Step [300 / 469], Generator Loss : 1.8454487323760986, Discriminator Loss : 0.6048009991645813\n",
            "Epoch [4 / 200], Step [400 / 469], Generator Loss : 0.8524553179740906, Discriminator Loss : 0.647386372089386\n",
            "Epoch [5 / 200], Step [100 / 469], Generator Loss : 1.6612058877944946, Discriminator Loss : 0.48821765184402466\n",
            "Epoch [5 / 200], Step [200 / 469], Generator Loss : 4.165515899658203, Discriminator Loss : 0.34100985527038574\n",
            "Epoch [5 / 200], Step [300 / 469], Generator Loss : 1.1580002307891846, Discriminator Loss : 0.5620108842849731\n",
            "Epoch [5 / 200], Step [400 / 469], Generator Loss : 2.187406539916992, Discriminator Loss : 0.5890646576881409\n",
            "Epoch [6 / 200], Step [100 / 469], Generator Loss : 3.9958229064941406, Discriminator Loss : 0.6170843839645386\n",
            "Epoch [6 / 200], Step [200 / 469], Generator Loss : 1.3432992696762085, Discriminator Loss : 0.49324899911880493\n",
            "Epoch [6 / 200], Step [300 / 469], Generator Loss : 6.645269393920898, Discriminator Loss : 1.4364628791809082\n",
            "Epoch [6 / 200], Step [400 / 469], Generator Loss : 1.4272279739379883, Discriminator Loss : 0.3992960453033447\n",
            "Epoch [7 / 200], Step [100 / 469], Generator Loss : 2.9468941688537598, Discriminator Loss : 0.5709944367408752\n",
            "Epoch [7 / 200], Step [200 / 469], Generator Loss : 1.7891919612884521, Discriminator Loss : 0.5413462519645691\n",
            "Epoch [7 / 200], Step [300 / 469], Generator Loss : 4.286227703094482, Discriminator Loss : 0.6058282256126404\n",
            "Epoch [7 / 200], Step [400 / 469], Generator Loss : 1.7165675163269043, Discriminator Loss : 0.3576076030731201\n",
            "Epoch [8 / 200], Step [100 / 469], Generator Loss : 2.0898728370666504, Discriminator Loss : 0.6249815225601196\n",
            "Epoch [8 / 200], Step [200 / 469], Generator Loss : 3.31534481048584, Discriminator Loss : 0.4628075361251831\n",
            "Epoch [8 / 200], Step [300 / 469], Generator Loss : 2.2645397186279297, Discriminator Loss : 0.5773758292198181\n",
            "Epoch [8 / 200], Step [400 / 469], Generator Loss : 1.7614271640777588, Discriminator Loss : 0.589036762714386\n",
            "Epoch [9 / 200], Step [100 / 469], Generator Loss : 2.0253753662109375, Discriminator Loss : 0.29118406772613525\n",
            "Epoch [9 / 200], Step [200 / 469], Generator Loss : 7.797235488891602, Discriminator Loss : 2.008030652999878\n",
            "Epoch [9 / 200], Step [300 / 469], Generator Loss : 1.456820011138916, Discriminator Loss : 0.5404149293899536\n",
            "Epoch [9 / 200], Step [400 / 469], Generator Loss : 1.576537013053894, Discriminator Loss : 0.4355964660644531\n",
            "Epoch [10 / 200], Step [100 / 469], Generator Loss : 2.4778518676757812, Discriminator Loss : 0.72049880027771\n",
            "Epoch [10 / 200], Step [200 / 469], Generator Loss : 0.24047335982322693, Discriminator Loss : 1.726292371749878\n",
            "Epoch [10 / 200], Step [300 / 469], Generator Loss : 1.4154361486434937, Discriminator Loss : 0.5100014209747314\n",
            "Epoch [10 / 200], Step [400 / 469], Generator Loss : 2.089531421661377, Discriminator Loss : 0.3492199182510376\n",
            "Epoch [11 / 200], Step [100 / 469], Generator Loss : 1.582830786705017, Discriminator Loss : 0.36526045203208923\n",
            "Epoch [11 / 200], Step [200 / 469], Generator Loss : 2.2271904945373535, Discriminator Loss : 0.2980800271034241\n",
            "Epoch [11 / 200], Step [300 / 469], Generator Loss : 1.6221935749053955, Discriminator Loss : 0.3743935227394104\n",
            "Epoch [11 / 200], Step [400 / 469], Generator Loss : 2.0950398445129395, Discriminator Loss : 0.4407062232494354\n",
            "Epoch [12 / 200], Step [100 / 469], Generator Loss : 2.954636573791504, Discriminator Loss : 0.1865740418434143\n",
            "Epoch [12 / 200], Step [200 / 469], Generator Loss : 1.836585283279419, Discriminator Loss : 0.3219155967235565\n",
            "Epoch [12 / 200], Step [300 / 469], Generator Loss : 1.8714070320129395, Discriminator Loss : 0.2978123128414154\n",
            "Epoch [12 / 200], Step [400 / 469], Generator Loss : 0.9298639297485352, Discriminator Loss : 0.7749629020690918\n",
            "Epoch [13 / 200], Step [100 / 469], Generator Loss : 2.1879749298095703, Discriminator Loss : 0.47125598788261414\n",
            "Epoch [13 / 200], Step [200 / 469], Generator Loss : 2.5099053382873535, Discriminator Loss : 0.3584425449371338\n",
            "Epoch [13 / 200], Step [300 / 469], Generator Loss : 1.4330532550811768, Discriminator Loss : 0.42108458280563354\n",
            "Epoch [13 / 200], Step [400 / 469], Generator Loss : 1.679306149482727, Discriminator Loss : 0.3626679480075836\n",
            "Epoch [14 / 200], Step [100 / 469], Generator Loss : 1.7535793781280518, Discriminator Loss : 0.2697332203388214\n",
            "Epoch [14 / 200], Step [200 / 469], Generator Loss : 4.4202704429626465, Discriminator Loss : 0.5128286480903625\n",
            "Epoch [14 / 200], Step [300 / 469], Generator Loss : 2.4339404106140137, Discriminator Loss : 0.2822217345237732\n",
            "Epoch [14 / 200], Step [400 / 469], Generator Loss : 5.554008960723877, Discriminator Loss : 0.7895781993865967\n",
            "Epoch [15 / 200], Step [100 / 469], Generator Loss : 3.290959119796753, Discriminator Loss : 0.2711649537086487\n",
            "Epoch [15 / 200], Step [200 / 469], Generator Loss : 3.2158186435699463, Discriminator Loss : 0.26209813356399536\n",
            "Epoch [15 / 200], Step [300 / 469], Generator Loss : 3.216259479522705, Discriminator Loss : 0.34709280729293823\n",
            "Epoch [15 / 200], Step [400 / 469], Generator Loss : 1.0920498371124268, Discriminator Loss : 0.6531417369842529\n",
            "Epoch [16 / 200], Step [100 / 469], Generator Loss : 2.228468418121338, Discriminator Loss : 0.476299911737442\n",
            "Epoch [16 / 200], Step [200 / 469], Generator Loss : 1.7509751319885254, Discriminator Loss : 0.4090365767478943\n",
            "Epoch [16 / 200], Step [300 / 469], Generator Loss : 3.171989679336548, Discriminator Loss : 0.47397276759147644\n",
            "Epoch [16 / 200], Step [400 / 469], Generator Loss : 1.7142878770828247, Discriminator Loss : 0.4075419008731842\n",
            "Epoch [17 / 200], Step [100 / 469], Generator Loss : 2.9060475826263428, Discriminator Loss : 0.3640953302383423\n",
            "Epoch [17 / 200], Step [200 / 469], Generator Loss : 1.4256060123443604, Discriminator Loss : 0.4423849582672119\n",
            "Epoch [17 / 200], Step [300 / 469], Generator Loss : 3.42630934715271, Discriminator Loss : 0.2102472335100174\n",
            "Epoch [17 / 200], Step [400 / 469], Generator Loss : 1.743863582611084, Discriminator Loss : 0.4275349974632263\n",
            "Epoch [18 / 200], Step [100 / 469], Generator Loss : 2.035342216491699, Discriminator Loss : 0.387775182723999\n",
            "Epoch [18 / 200], Step [200 / 469], Generator Loss : 3.807734489440918, Discriminator Loss : 0.29686057567596436\n",
            "Epoch [18 / 200], Step [300 / 469], Generator Loss : 1.157381296157837, Discriminator Loss : 0.6460801959037781\n",
            "Epoch [18 / 200], Step [400 / 469], Generator Loss : 3.1382687091827393, Discriminator Loss : 0.49475276470184326\n",
            "Epoch [19 / 200], Step [100 / 469], Generator Loss : 6.274733543395996, Discriminator Loss : 1.0463430881500244\n",
            "Epoch [19 / 200], Step [200 / 469], Generator Loss : 5.320836067199707, Discriminator Loss : 0.9061436653137207\n",
            "Epoch [19 / 200], Step [300 / 469], Generator Loss : 1.9102799892425537, Discriminator Loss : 0.3848172724246979\n",
            "Epoch [19 / 200], Step [400 / 469], Generator Loss : 2.6716980934143066, Discriminator Loss : 0.26326149702072144\n",
            "Epoch [20 / 200], Step [100 / 469], Generator Loss : 2.2877488136291504, Discriminator Loss : 0.36987462639808655\n",
            "Epoch [20 / 200], Step [200 / 469], Generator Loss : 2.294374465942383, Discriminator Loss : 0.6182435154914856\n",
            "Epoch [20 / 200], Step [300 / 469], Generator Loss : 4.626045227050781, Discriminator Loss : 0.12611478567123413\n",
            "Epoch [20 / 200], Step [400 / 469], Generator Loss : 5.504334449768066, Discriminator Loss : 0.6180959939956665\n",
            "Epoch [21 / 200], Step [100 / 469], Generator Loss : 5.329263687133789, Discriminator Loss : 0.3685614764690399\n",
            "Epoch [21 / 200], Step [200 / 469], Generator Loss : 3.576944351196289, Discriminator Loss : 0.12440076470375061\n",
            "Epoch [21 / 200], Step [300 / 469], Generator Loss : 3.1573173999786377, Discriminator Loss : 0.16798916459083557\n",
            "Epoch [21 / 200], Step [400 / 469], Generator Loss : 2.919340133666992, Discriminator Loss : 0.20631922781467438\n",
            "Epoch [22 / 200], Step [100 / 469], Generator Loss : 10.715425491333008, Discriminator Loss : 3.2044317722320557\n",
            "Epoch [22 / 200], Step [200 / 469], Generator Loss : 2.1071035861968994, Discriminator Loss : 0.45944786071777344\n",
            "Epoch [22 / 200], Step [300 / 469], Generator Loss : 2.770127534866333, Discriminator Loss : 0.23600511252880096\n",
            "Epoch [22 / 200], Step [400 / 469], Generator Loss : 1.6381769180297852, Discriminator Loss : 0.34535032510757446\n",
            "Epoch [23 / 200], Step [100 / 469], Generator Loss : 2.694296360015869, Discriminator Loss : 0.4386162757873535\n",
            "Epoch [23 / 200], Step [200 / 469], Generator Loss : 1.9031012058258057, Discriminator Loss : 0.3144652247428894\n",
            "Epoch [23 / 200], Step [300 / 469], Generator Loss : 2.3570632934570312, Discriminator Loss : 0.2287927269935608\n",
            "Epoch [23 / 200], Step [400 / 469], Generator Loss : 3.0794544219970703, Discriminator Loss : 0.40375587344169617\n",
            "Epoch [24 / 200], Step [100 / 469], Generator Loss : 2.7402777671813965, Discriminator Loss : 0.23709923028945923\n",
            "Epoch [24 / 200], Step [200 / 469], Generator Loss : 1.708983302116394, Discriminator Loss : 0.3524806499481201\n",
            "Epoch [24 / 200], Step [300 / 469], Generator Loss : 4.007534027099609, Discriminator Loss : 0.2772204279899597\n",
            "Epoch [24 / 200], Step [400 / 469], Generator Loss : 2.711493968963623, Discriminator Loss : 0.3397107720375061\n",
            "Epoch [25 / 200], Step [100 / 469], Generator Loss : 5.587987899780273, Discriminator Loss : 0.5207210183143616\n",
            "Epoch [25 / 200], Step [200 / 469], Generator Loss : 1.8674299716949463, Discriminator Loss : 0.3110004663467407\n",
            "Epoch [25 / 200], Step [300 / 469], Generator Loss : 2.9726693630218506, Discriminator Loss : 0.4431621730327606\n",
            "Epoch [25 / 200], Step [400 / 469], Generator Loss : 2.3285040855407715, Discriminator Loss : 0.37899601459503174\n",
            "Epoch [26 / 200], Step [100 / 469], Generator Loss : 4.226728916168213, Discriminator Loss : 0.21026474237442017\n",
            "Epoch [26 / 200], Step [200 / 469], Generator Loss : 1.7008802890777588, Discriminator Loss : 0.4082644581794739\n",
            "Epoch [26 / 200], Step [300 / 469], Generator Loss : 2.4676737785339355, Discriminator Loss : 0.3640176057815552\n",
            "Epoch [26 / 200], Step [400 / 469], Generator Loss : 2.9220633506774902, Discriminator Loss : 0.3358188271522522\n",
            "Epoch [27 / 200], Step [100 / 469], Generator Loss : 2.1347761154174805, Discriminator Loss : 0.4778980612754822\n",
            "Epoch [27 / 200], Step [200 / 469], Generator Loss : 2.374448299407959, Discriminator Loss : 0.3147814869880676\n",
            "Epoch [27 / 200], Step [300 / 469], Generator Loss : 3.0104565620422363, Discriminator Loss : 0.31215012073516846\n",
            "Epoch [27 / 200], Step [400 / 469], Generator Loss : 1.3067505359649658, Discriminator Loss : 0.44153037667274475\n",
            "Epoch [28 / 200], Step [100 / 469], Generator Loss : 2.148988723754883, Discriminator Loss : 0.3391011357307434\n",
            "Epoch [28 / 200], Step [200 / 469], Generator Loss : 1.655238151550293, Discriminator Loss : 0.4180499315261841\n",
            "Epoch [28 / 200], Step [300 / 469], Generator Loss : 2.8511877059936523, Discriminator Loss : 0.2507516145706177\n",
            "Epoch [28 / 200], Step [400 / 469], Generator Loss : 4.218875408172607, Discriminator Loss : 0.23455435037612915\n",
            "Epoch [29 / 200], Step [100 / 469], Generator Loss : 1.1676905155181885, Discriminator Loss : 0.5591754913330078\n",
            "Epoch [29 / 200], Step [200 / 469], Generator Loss : 2.374897003173828, Discriminator Loss : 0.3692762553691864\n",
            "Epoch [29 / 200], Step [300 / 469], Generator Loss : 2.0270817279815674, Discriminator Loss : 0.3427979350090027\n",
            "Epoch [29 / 200], Step [400 / 469], Generator Loss : 4.138581275939941, Discriminator Loss : 0.42544910311698914\n",
            "Epoch [30 / 200], Step [100 / 469], Generator Loss : 3.136587619781494, Discriminator Loss : 0.24264511466026306\n",
            "Epoch [30 / 200], Step [200 / 469], Generator Loss : 3.099602699279785, Discriminator Loss : 0.31240320205688477\n",
            "Epoch [30 / 200], Step [300 / 469], Generator Loss : 2.155764102935791, Discriminator Loss : 0.35547688603401184\n",
            "Epoch [30 / 200], Step [400 / 469], Generator Loss : 7.3984527587890625, Discriminator Loss : 0.5022112727165222\n",
            "Epoch [31 / 200], Step [100 / 469], Generator Loss : 1.2789347171783447, Discriminator Loss : 0.5530465245246887\n",
            "Epoch [31 / 200], Step [200 / 469], Generator Loss : 2.633695363998413, Discriminator Loss : 0.29092758893966675\n",
            "Epoch [31 / 200], Step [300 / 469], Generator Loss : 2.3526952266693115, Discriminator Loss : 0.3044395446777344\n",
            "Epoch [31 / 200], Step [400 / 469], Generator Loss : 1.871774435043335, Discriminator Loss : 0.8236058354377747\n",
            "Epoch [32 / 200], Step [100 / 469], Generator Loss : 2.787275791168213, Discriminator Loss : 0.2592615485191345\n",
            "Epoch [32 / 200], Step [200 / 469], Generator Loss : 2.7754666805267334, Discriminator Loss : 0.2732538878917694\n",
            "Epoch [32 / 200], Step [300 / 469], Generator Loss : 4.259859561920166, Discriminator Loss : 0.17417068779468536\n",
            "Epoch [32 / 200], Step [400 / 469], Generator Loss : 2.8362717628479004, Discriminator Loss : 0.5544601678848267\n",
            "Epoch [33 / 200], Step [100 / 469], Generator Loss : 2.5140018463134766, Discriminator Loss : 0.4047423005104065\n",
            "Epoch [33 / 200], Step [200 / 469], Generator Loss : 2.5798726081848145, Discriminator Loss : 0.20779620110988617\n",
            "Epoch [33 / 200], Step [300 / 469], Generator Loss : 1.6174311637878418, Discriminator Loss : 0.5581769943237305\n",
            "Epoch [33 / 200], Step [400 / 469], Generator Loss : 1.9875270128250122, Discriminator Loss : 0.3254010081291199\n",
            "Epoch [34 / 200], Step [100 / 469], Generator Loss : 2.2677526473999023, Discriminator Loss : 0.3200646638870239\n",
            "Epoch [34 / 200], Step [200 / 469], Generator Loss : 3.5867738723754883, Discriminator Loss : 0.28837358951568604\n",
            "Epoch [34 / 200], Step [300 / 469], Generator Loss : 2.355525493621826, Discriminator Loss : 0.3074718117713928\n",
            "Epoch [34 / 200], Step [400 / 469], Generator Loss : 4.018699645996094, Discriminator Loss : 0.2672785520553589\n",
            "Epoch [35 / 200], Step [100 / 469], Generator Loss : 2.6637823581695557, Discriminator Loss : 0.3149266242980957\n",
            "Epoch [35 / 200], Step [200 / 469], Generator Loss : 1.5759207010269165, Discriminator Loss : 0.3859961926937103\n",
            "Epoch [35 / 200], Step [300 / 469], Generator Loss : 1.6382837295532227, Discriminator Loss : 0.4168415665626526\n",
            "Epoch [35 / 200], Step [400 / 469], Generator Loss : 2.5060997009277344, Discriminator Loss : 0.262424111366272\n",
            "Epoch [36 / 200], Step [100 / 469], Generator Loss : 2.387338638305664, Discriminator Loss : 0.16422933340072632\n",
            "Epoch [36 / 200], Step [200 / 469], Generator Loss : 7.168220043182373, Discriminator Loss : 0.6766971349716187\n",
            "Epoch [36 / 200], Step [300 / 469], Generator Loss : 1.511019229888916, Discriminator Loss : 0.5725197196006775\n",
            "Epoch [36 / 200], Step [400 / 469], Generator Loss : 2.6145806312561035, Discriminator Loss : 0.3763398230075836\n",
            "Epoch [37 / 200], Step [100 / 469], Generator Loss : 2.6621015071868896, Discriminator Loss : 0.25750732421875\n",
            "Epoch [37 / 200], Step [200 / 469], Generator Loss : 1.4863836765289307, Discriminator Loss : 0.6395252346992493\n",
            "Epoch [37 / 200], Step [300 / 469], Generator Loss : 2.165888547897339, Discriminator Loss : 0.43212026357650757\n",
            "Epoch [37 / 200], Step [400 / 469], Generator Loss : 1.5588147640228271, Discriminator Loss : 0.34356552362442017\n",
            "Epoch [38 / 200], Step [100 / 469], Generator Loss : 4.249117374420166, Discriminator Loss : 0.2226807028055191\n",
            "Epoch [38 / 200], Step [200 / 469], Generator Loss : 4.219307899475098, Discriminator Loss : 0.5045427680015564\n",
            "Epoch [38 / 200], Step [300 / 469], Generator Loss : 1.04185152053833, Discriminator Loss : 0.7062304019927979\n",
            "Epoch [38 / 200], Step [400 / 469], Generator Loss : 2.9921469688415527, Discriminator Loss : 0.1934601217508316\n",
            "Epoch [39 / 200], Step [100 / 469], Generator Loss : 2.6627798080444336, Discriminator Loss : 0.41598057746887207\n",
            "Epoch [39 / 200], Step [200 / 469], Generator Loss : 3.464022159576416, Discriminator Loss : 0.37746405601501465\n",
            "Epoch [39 / 200], Step [300 / 469], Generator Loss : 2.7232584953308105, Discriminator Loss : 0.1442354917526245\n",
            "Epoch [39 / 200], Step [400 / 469], Generator Loss : 5.104605674743652, Discriminator Loss : 0.41526657342910767\n",
            "Epoch [40 / 200], Step [100 / 469], Generator Loss : 0.4433431029319763, Discriminator Loss : 2.1208040714263916\n",
            "Epoch [40 / 200], Step [200 / 469], Generator Loss : 2.8503479957580566, Discriminator Loss : 0.27890029549598694\n",
            "Epoch [40 / 200], Step [300 / 469], Generator Loss : 4.096682548522949, Discriminator Loss : 0.4751500189304352\n",
            "Epoch [40 / 200], Step [400 / 469], Generator Loss : 2.681267499923706, Discriminator Loss : 0.26380378007888794\n",
            "Epoch [41 / 200], Step [100 / 469], Generator Loss : 1.5766539573669434, Discriminator Loss : 0.4247582256793976\n",
            "Epoch [41 / 200], Step [200 / 469], Generator Loss : 3.8508503437042236, Discriminator Loss : 0.14558400213718414\n",
            "Epoch [41 / 200], Step [300 / 469], Generator Loss : 2.150332450866699, Discriminator Loss : 0.2926992177963257\n",
            "Epoch [41 / 200], Step [400 / 469], Generator Loss : 7.303425312042236, Discriminator Loss : 0.7886927723884583\n",
            "Epoch [42 / 200], Step [100 / 469], Generator Loss : 2.5000505447387695, Discriminator Loss : 0.19183249771595\n",
            "Epoch [42 / 200], Step [200 / 469], Generator Loss : 1.7701807022094727, Discriminator Loss : 0.5942962765693665\n",
            "Epoch [42 / 200], Step [300 / 469], Generator Loss : 3.0556271076202393, Discriminator Loss : 0.3783535063266754\n",
            "Epoch [42 / 200], Step [400 / 469], Generator Loss : 0.6326311230659485, Discriminator Loss : 0.9873461723327637\n",
            "Epoch [43 / 200], Step [100 / 469], Generator Loss : 3.854621410369873, Discriminator Loss : 0.4136430621147156\n",
            "Epoch [43 / 200], Step [200 / 469], Generator Loss : 3.8680477142333984, Discriminator Loss : 0.47394680976867676\n",
            "Epoch [43 / 200], Step [300 / 469], Generator Loss : 3.2377374172210693, Discriminator Loss : 0.2372940480709076\n",
            "Epoch [43 / 200], Step [400 / 469], Generator Loss : 2.7670483589172363, Discriminator Loss : 0.2138361781835556\n",
            "Epoch [44 / 200], Step [100 / 469], Generator Loss : 1.942084789276123, Discriminator Loss : 0.41986867785453796\n",
            "Epoch [44 / 200], Step [200 / 469], Generator Loss : 4.591926574707031, Discriminator Loss : 0.2396569848060608\n",
            "Epoch [44 / 200], Step [300 / 469], Generator Loss : 1.4054417610168457, Discriminator Loss : 0.49378204345703125\n",
            "Epoch [44 / 200], Step [400 / 469], Generator Loss : 1.7500249147415161, Discriminator Loss : 0.5811657905578613\n",
            "Epoch [45 / 200], Step [100 / 469], Generator Loss : 1.8732775449752808, Discriminator Loss : 0.4809226989746094\n",
            "Epoch [45 / 200], Step [200 / 469], Generator Loss : 3.600403308868408, Discriminator Loss : 0.3792177438735962\n",
            "Epoch [45 / 200], Step [300 / 469], Generator Loss : 3.0861239433288574, Discriminator Loss : 0.24200373888015747\n",
            "Epoch [45 / 200], Step [400 / 469], Generator Loss : 1.7910583019256592, Discriminator Loss : 0.2661997079849243\n",
            "Epoch [46 / 200], Step [100 / 469], Generator Loss : 3.1916065216064453, Discriminator Loss : 0.2945522367954254\n",
            "Epoch [46 / 200], Step [200 / 469], Generator Loss : 3.155547618865967, Discriminator Loss : 0.3222750127315521\n",
            "Epoch [46 / 200], Step [300 / 469], Generator Loss : 3.484938144683838, Discriminator Loss : 0.3194234073162079\n",
            "Epoch [46 / 200], Step [400 / 469], Generator Loss : 2.5555286407470703, Discriminator Loss : 0.457032710313797\n",
            "Epoch [47 / 200], Step [100 / 469], Generator Loss : 1.7434535026550293, Discriminator Loss : 0.33867260813713074\n",
            "Epoch [47 / 200], Step [200 / 469], Generator Loss : 2.8460588455200195, Discriminator Loss : 0.3831297755241394\n",
            "Epoch [47 / 200], Step [300 / 469], Generator Loss : 2.6013317108154297, Discriminator Loss : 0.19970008730888367\n",
            "Epoch [47 / 200], Step [400 / 469], Generator Loss : 1.9773879051208496, Discriminator Loss : 0.47969087958335876\n",
            "Epoch [48 / 200], Step [100 / 469], Generator Loss : 1.4232609272003174, Discriminator Loss : 0.44208499789237976\n",
            "Epoch [48 / 200], Step [200 / 469], Generator Loss : 1.6594985723495483, Discriminator Loss : 0.3954182267189026\n",
            "Epoch [48 / 200], Step [300 / 469], Generator Loss : 2.282042980194092, Discriminator Loss : 0.2861812710762024\n",
            "Epoch [48 / 200], Step [400 / 469], Generator Loss : 2.5763683319091797, Discriminator Loss : 0.4270816743373871\n",
            "Epoch [49 / 200], Step [100 / 469], Generator Loss : 2.5844736099243164, Discriminator Loss : 0.4402916431427002\n",
            "Epoch [49 / 200], Step [200 / 469], Generator Loss : 1.700317144393921, Discriminator Loss : 0.34166789054870605\n",
            "Epoch [49 / 200], Step [300 / 469], Generator Loss : 1.6381319761276245, Discriminator Loss : 0.4636906683444977\n",
            "Epoch [49 / 200], Step [400 / 469], Generator Loss : 8.22210693359375, Discriminator Loss : 1.70843505859375\n",
            "Epoch [50 / 200], Step [100 / 469], Generator Loss : 1.718159794807434, Discriminator Loss : 0.46574246883392334\n",
            "Epoch [50 / 200], Step [200 / 469], Generator Loss : 4.589238166809082, Discriminator Loss : 0.2095234990119934\n",
            "Epoch [50 / 200], Step [300 / 469], Generator Loss : 3.0243897438049316, Discriminator Loss : 0.4138329029083252\n",
            "Epoch [50 / 200], Step [400 / 469], Generator Loss : 3.5990982055664062, Discriminator Loss : 0.284523069858551\n",
            "Epoch [51 / 200], Step [100 / 469], Generator Loss : 6.411995887756348, Discriminator Loss : 0.6020668745040894\n",
            "Epoch [51 / 200], Step [200 / 469], Generator Loss : 2.2205591201782227, Discriminator Loss : 0.4026464819908142\n",
            "Epoch [51 / 200], Step [300 / 469], Generator Loss : 3.052715301513672, Discriminator Loss : 0.22325119376182556\n",
            "Epoch [51 / 200], Step [400 / 469], Generator Loss : 3.0943288803100586, Discriminator Loss : 0.24733909964561462\n",
            "Epoch [52 / 200], Step [100 / 469], Generator Loss : 2.2612767219543457, Discriminator Loss : 0.3046933114528656\n",
            "Epoch [52 / 200], Step [200 / 469], Generator Loss : 4.30251407623291, Discriminator Loss : 0.2035410851240158\n",
            "Epoch [52 / 200], Step [300 / 469], Generator Loss : 2.0844979286193848, Discriminator Loss : 0.39998066425323486\n",
            "Epoch [52 / 200], Step [400 / 469], Generator Loss : 2.940960168838501, Discriminator Loss : 0.2398170530796051\n",
            "Epoch [53 / 200], Step [100 / 469], Generator Loss : 3.2234320640563965, Discriminator Loss : 0.25614133477211\n",
            "Epoch [53 / 200], Step [200 / 469], Generator Loss : 2.8640592098236084, Discriminator Loss : 0.21192844212055206\n",
            "Epoch [53 / 200], Step [300 / 469], Generator Loss : 1.7924468517303467, Discriminator Loss : 0.5330761075019836\n",
            "Epoch [53 / 200], Step [400 / 469], Generator Loss : 2.610382080078125, Discriminator Loss : 0.43021824955940247\n",
            "Epoch [54 / 200], Step [100 / 469], Generator Loss : 1.570411205291748, Discriminator Loss : 0.40685296058654785\n",
            "Epoch [54 / 200], Step [200 / 469], Generator Loss : 4.974286079406738, Discriminator Loss : 0.36125507950782776\n",
            "Epoch [54 / 200], Step [300 / 469], Generator Loss : 1.9247009754180908, Discriminator Loss : 0.3379375636577606\n",
            "Epoch [54 / 200], Step [400 / 469], Generator Loss : 4.231781959533691, Discriminator Loss : 0.5923905372619629\n",
            "Epoch [55 / 200], Step [100 / 469], Generator Loss : 3.1394705772399902, Discriminator Loss : 0.10011717677116394\n",
            "Epoch [55 / 200], Step [200 / 469], Generator Loss : 3.293109893798828, Discriminator Loss : 0.3743413984775543\n",
            "Epoch [55 / 200], Step [300 / 469], Generator Loss : 2.913388967514038, Discriminator Loss : 0.23649561405181885\n",
            "Epoch [55 / 200], Step [400 / 469], Generator Loss : 1.401047706604004, Discriminator Loss : 0.5349258780479431\n",
            "Epoch [56 / 200], Step [100 / 469], Generator Loss : 2.6298205852508545, Discriminator Loss : 0.27796655893325806\n",
            "Epoch [56 / 200], Step [200 / 469], Generator Loss : 1.751317024230957, Discriminator Loss : 0.3076338469982147\n",
            "Epoch [56 / 200], Step [300 / 469], Generator Loss : 1.9127615690231323, Discriminator Loss : 0.34876519441604614\n",
            "Epoch [56 / 200], Step [400 / 469], Generator Loss : 1.590684413909912, Discriminator Loss : 0.35981157422065735\n",
            "Epoch [57 / 200], Step [100 / 469], Generator Loss : 1.728470802307129, Discriminator Loss : 0.3804469108581543\n",
            "Epoch [57 / 200], Step [200 / 469], Generator Loss : 1.3533921241760254, Discriminator Loss : 0.586455225944519\n",
            "Epoch [57 / 200], Step [300 / 469], Generator Loss : 2.8816328048706055, Discriminator Loss : 0.38746321201324463\n",
            "Epoch [57 / 200], Step [400 / 469], Generator Loss : 2.9545936584472656, Discriminator Loss : 0.19718122482299805\n",
            "Epoch [58 / 200], Step [100 / 469], Generator Loss : 2.3572654724121094, Discriminator Loss : 0.3300517797470093\n",
            "Epoch [58 / 200], Step [200 / 469], Generator Loss : 1.4183349609375, Discriminator Loss : 0.5810822248458862\n",
            "Epoch [58 / 200], Step [300 / 469], Generator Loss : 5.5147624015808105, Discriminator Loss : 0.7703492641448975\n",
            "Epoch [58 / 200], Step [400 / 469], Generator Loss : 2.6837499141693115, Discriminator Loss : 0.26726648211479187\n",
            "Epoch [59 / 200], Step [100 / 469], Generator Loss : 6.968857765197754, Discriminator Loss : 1.36045241355896\n",
            "Epoch [59 / 200], Step [200 / 469], Generator Loss : 2.0181994438171387, Discriminator Loss : 0.5395169258117676\n",
            "Epoch [59 / 200], Step [300 / 469], Generator Loss : 1.7146881818771362, Discriminator Loss : 0.42036595940589905\n",
            "Epoch [59 / 200], Step [400 / 469], Generator Loss : 2.2521255016326904, Discriminator Loss : 0.3523043394088745\n",
            "Epoch [60 / 200], Step [100 / 469], Generator Loss : 3.006464958190918, Discriminator Loss : 0.3116247057914734\n",
            "Epoch [60 / 200], Step [200 / 469], Generator Loss : 1.6831612586975098, Discriminator Loss : 0.4953988194465637\n",
            "Epoch [60 / 200], Step [300 / 469], Generator Loss : 2.695812702178955, Discriminator Loss : 0.397816002368927\n",
            "Epoch [60 / 200], Step [400 / 469], Generator Loss : 1.8818249702453613, Discriminator Loss : 0.436505526304245\n",
            "Epoch [61 / 200], Step [100 / 469], Generator Loss : 4.239823341369629, Discriminator Loss : 1.0106661319732666\n",
            "Epoch [61 / 200], Step [200 / 469], Generator Loss : 6.185554504394531, Discriminator Loss : 1.1333194971084595\n",
            "Epoch [61 / 200], Step [300 / 469], Generator Loss : 1.8965532779693604, Discriminator Loss : 0.38943809270858765\n",
            "Epoch [61 / 200], Step [400 / 469], Generator Loss : 2.753674030303955, Discriminator Loss : 0.21753957867622375\n",
            "Epoch [62 / 200], Step [100 / 469], Generator Loss : 2.2873520851135254, Discriminator Loss : 0.30274420976638794\n",
            "Epoch [62 / 200], Step [200 / 469], Generator Loss : 3.9359257221221924, Discriminator Loss : 0.5326899290084839\n",
            "Epoch [62 / 200], Step [300 / 469], Generator Loss : 4.306421279907227, Discriminator Loss : 0.6233052015304565\n",
            "Epoch [62 / 200], Step [400 / 469], Generator Loss : 2.697154998779297, Discriminator Loss : 0.4163849949836731\n",
            "Epoch [63 / 200], Step [100 / 469], Generator Loss : 6.274941921234131, Discriminator Loss : 0.8805367946624756\n",
            "Epoch [63 / 200], Step [200 / 469], Generator Loss : 2.1702122688293457, Discriminator Loss : 0.39701011776924133\n",
            "Epoch [63 / 200], Step [300 / 469], Generator Loss : 2.6582412719726562, Discriminator Loss : 0.29162371158599854\n",
            "Epoch [63 / 200], Step [400 / 469], Generator Loss : 2.445148468017578, Discriminator Loss : 0.3787866234779358\n",
            "Epoch [64 / 200], Step [100 / 469], Generator Loss : 0.992874264717102, Discriminator Loss : 0.7879928946495056\n",
            "Epoch [64 / 200], Step [200 / 469], Generator Loss : 2.424243688583374, Discriminator Loss : 0.46610426902770996\n",
            "Epoch [64 / 200], Step [300 / 469], Generator Loss : 2.4260404109954834, Discriminator Loss : 0.38353365659713745\n",
            "Epoch [64 / 200], Step [400 / 469], Generator Loss : 2.1464967727661133, Discriminator Loss : 0.5836910009384155\n",
            "Epoch [65 / 200], Step [100 / 469], Generator Loss : 2.810594081878662, Discriminator Loss : 0.7262782454490662\n",
            "Epoch [65 / 200], Step [200 / 469], Generator Loss : 2.411176919937134, Discriminator Loss : 0.5351661443710327\n",
            "Epoch [65 / 200], Step [300 / 469], Generator Loss : 3.398885726928711, Discriminator Loss : 0.4376913011074066\n",
            "Epoch [65 / 200], Step [400 / 469], Generator Loss : 2.366267681121826, Discriminator Loss : 0.29679450392723083\n",
            "Epoch [66 / 200], Step [100 / 469], Generator Loss : 2.616410970687866, Discriminator Loss : 0.29250431060791016\n",
            "Epoch [66 / 200], Step [200 / 469], Generator Loss : 1.2734472751617432, Discriminator Loss : 0.49777132272720337\n",
            "Epoch [66 / 200], Step [300 / 469], Generator Loss : 1.7808376550674438, Discriminator Loss : 0.30458563566207886\n",
            "Epoch [66 / 200], Step [400 / 469], Generator Loss : 1.919623851776123, Discriminator Loss : 0.7821275591850281\n",
            "Epoch [67 / 200], Step [100 / 469], Generator Loss : 0.9900219440460205, Discriminator Loss : 0.6698977947235107\n",
            "Epoch [67 / 200], Step [200 / 469], Generator Loss : 3.5983591079711914, Discriminator Loss : 0.4840678572654724\n",
            "Epoch [67 / 200], Step [300 / 469], Generator Loss : 2.6906578540802, Discriminator Loss : 0.3154703974723816\n",
            "Epoch [67 / 200], Step [400 / 469], Generator Loss : 2.842771291732788, Discriminator Loss : 0.22640232741832733\n",
            "Epoch [68 / 200], Step [100 / 469], Generator Loss : 2.828272819519043, Discriminator Loss : 0.35183197259902954\n",
            "Epoch [68 / 200], Step [200 / 469], Generator Loss : 1.7495574951171875, Discriminator Loss : 0.5287742614746094\n",
            "Epoch [68 / 200], Step [300 / 469], Generator Loss : 3.1512155532836914, Discriminator Loss : 0.20338153839111328\n",
            "Epoch [68 / 200], Step [400 / 469], Generator Loss : 1.7765848636627197, Discriminator Loss : 0.5673841238021851\n",
            "Epoch [69 / 200], Step [100 / 469], Generator Loss : 3.2349231243133545, Discriminator Loss : 0.23373816907405853\n",
            "Epoch [69 / 200], Step [200 / 469], Generator Loss : 2.658539295196533, Discriminator Loss : 0.41120970249176025\n",
            "Epoch [69 / 200], Step [300 / 469], Generator Loss : 1.8676021099090576, Discriminator Loss : 0.5423242449760437\n",
            "Epoch [69 / 200], Step [400 / 469], Generator Loss : 1.8904805183410645, Discriminator Loss : 0.3921470046043396\n",
            "Epoch [70 / 200], Step [100 / 469], Generator Loss : 2.667184352874756, Discriminator Loss : 0.23959097266197205\n",
            "Epoch [70 / 200], Step [200 / 469], Generator Loss : 3.1100645065307617, Discriminator Loss : 0.5739003419876099\n",
            "Epoch [70 / 200], Step [300 / 469], Generator Loss : 2.349600315093994, Discriminator Loss : 0.304414838552475\n",
            "Epoch [70 / 200], Step [400 / 469], Generator Loss : 3.872213840484619, Discriminator Loss : 0.63325434923172\n",
            "Epoch [71 / 200], Step [100 / 469], Generator Loss : 3.1580898761749268, Discriminator Loss : 0.5111967921257019\n",
            "Epoch [71 / 200], Step [200 / 469], Generator Loss : 2.4763731956481934, Discriminator Loss : 0.3547452986240387\n",
            "Epoch [71 / 200], Step [300 / 469], Generator Loss : 2.4863648414611816, Discriminator Loss : 0.3824799656867981\n",
            "Epoch [71 / 200], Step [400 / 469], Generator Loss : 2.195683002471924, Discriminator Loss : 0.3494240343570709\n",
            "Epoch [72 / 200], Step [100 / 469], Generator Loss : 3.269944667816162, Discriminator Loss : 0.3090898394584656\n",
            "Epoch [72 / 200], Step [200 / 469], Generator Loss : 2.1470589637756348, Discriminator Loss : 0.36791107058525085\n",
            "Epoch [72 / 200], Step [300 / 469], Generator Loss : 2.6363890171051025, Discriminator Loss : 0.29063645005226135\n",
            "Epoch [72 / 200], Step [400 / 469], Generator Loss : 3.3061933517456055, Discriminator Loss : 0.4393906891345978\n",
            "Epoch [73 / 200], Step [100 / 469], Generator Loss : 2.8782272338867188, Discriminator Loss : 0.2388630509376526\n",
            "Epoch [73 / 200], Step [200 / 469], Generator Loss : 4.537930011749268, Discriminator Loss : 0.4271124601364136\n",
            "Epoch [73 / 200], Step [300 / 469], Generator Loss : 2.1104118824005127, Discriminator Loss : 0.2968982458114624\n",
            "Epoch [73 / 200], Step [400 / 469], Generator Loss : 2.4862918853759766, Discriminator Loss : 0.2743385434150696\n",
            "Epoch [74 / 200], Step [100 / 469], Generator Loss : 3.8868494033813477, Discriminator Loss : 0.5050998330116272\n",
            "Epoch [74 / 200], Step [200 / 469], Generator Loss : 1.771682858467102, Discriminator Loss : 0.520899772644043\n",
            "Epoch [74 / 200], Step [300 / 469], Generator Loss : 1.619485855102539, Discriminator Loss : 0.5072053074836731\n",
            "Epoch [74 / 200], Step [400 / 469], Generator Loss : 4.268618583679199, Discriminator Loss : 0.42503994703292847\n",
            "Epoch [75 / 200], Step [100 / 469], Generator Loss : 3.2477574348449707, Discriminator Loss : 0.29845356941223145\n",
            "Epoch [75 / 200], Step [200 / 469], Generator Loss : 2.3538269996643066, Discriminator Loss : 0.40886932611465454\n",
            "Epoch [75 / 200], Step [300 / 469], Generator Loss : 3.659444808959961, Discriminator Loss : 0.48958390951156616\n",
            "Epoch [75 / 200], Step [400 / 469], Generator Loss : 2.9364423751831055, Discriminator Loss : 0.7185271978378296\n",
            "Epoch [76 / 200], Step [100 / 469], Generator Loss : 4.849154472351074, Discriminator Loss : 0.8055987358093262\n",
            "Epoch [76 / 200], Step [200 / 469], Generator Loss : 5.077571868896484, Discriminator Loss : 0.47908005118370056\n",
            "Epoch [76 / 200], Step [300 / 469], Generator Loss : 3.2947709560394287, Discriminator Loss : 0.3440221846103668\n",
            "Epoch [76 / 200], Step [400 / 469], Generator Loss : 3.5774500370025635, Discriminator Loss : 0.37920108437538147\n",
            "Epoch [77 / 200], Step [100 / 469], Generator Loss : 3.562931537628174, Discriminator Loss : 0.48447132110595703\n",
            "Epoch [77 / 200], Step [200 / 469], Generator Loss : 4.933581352233887, Discriminator Loss : 0.29489216208457947\n",
            "Epoch [77 / 200], Step [300 / 469], Generator Loss : 2.622150421142578, Discriminator Loss : 0.3516243100166321\n",
            "Epoch [77 / 200], Step [400 / 469], Generator Loss : 2.1468594074249268, Discriminator Loss : 0.3861668109893799\n",
            "Epoch [78 / 200], Step [100 / 469], Generator Loss : 3.0623202323913574, Discriminator Loss : 0.3633594810962677\n",
            "Epoch [78 / 200], Step [200 / 469], Generator Loss : 3.0407731533050537, Discriminator Loss : 0.40644577145576477\n",
            "Epoch [78 / 200], Step [300 / 469], Generator Loss : 2.4153051376342773, Discriminator Loss : 0.42184826731681824\n",
            "Epoch [78 / 200], Step [400 / 469], Generator Loss : 1.1250760555267334, Discriminator Loss : 0.6647852659225464\n",
            "Epoch [79 / 200], Step [100 / 469], Generator Loss : 5.036067962646484, Discriminator Loss : 0.6003020405769348\n",
            "Epoch [79 / 200], Step [200 / 469], Generator Loss : 1.7556334733963013, Discriminator Loss : 0.36576300859451294\n",
            "Epoch [79 / 200], Step [300 / 469], Generator Loss : 0.6484236717224121, Discriminator Loss : 0.9796738028526306\n",
            "Epoch [79 / 200], Step [400 / 469], Generator Loss : 1.6042264699935913, Discriminator Loss : 0.4211927652359009\n",
            "Epoch [80 / 200], Step [100 / 469], Generator Loss : 2.6257941722869873, Discriminator Loss : 0.2827233076095581\n",
            "Epoch [80 / 200], Step [200 / 469], Generator Loss : 3.2659051418304443, Discriminator Loss : 0.26204878091812134\n",
            "Epoch [80 / 200], Step [300 / 469], Generator Loss : 3.9664058685302734, Discriminator Loss : 0.34770089387893677\n",
            "Epoch [80 / 200], Step [400 / 469], Generator Loss : 3.1946191787719727, Discriminator Loss : 0.24982966482639313\n",
            "Epoch [81 / 200], Step [100 / 469], Generator Loss : 3.2457470893859863, Discriminator Loss : 0.3584161400794983\n",
            "Epoch [81 / 200], Step [200 / 469], Generator Loss : 1.6796071529388428, Discriminator Loss : 0.4629800319671631\n",
            "Epoch [81 / 200], Step [300 / 469], Generator Loss : 2.449882745742798, Discriminator Loss : 0.38076651096343994\n",
            "Epoch [81 / 200], Step [400 / 469], Generator Loss : 2.3709306716918945, Discriminator Loss : 0.3605858385562897\n",
            "Epoch [82 / 200], Step [100 / 469], Generator Loss : 4.911775588989258, Discriminator Loss : 0.7132461667060852\n",
            "Epoch [82 / 200], Step [200 / 469], Generator Loss : 2.288800001144409, Discriminator Loss : 0.43742552399635315\n",
            "Epoch [82 / 200], Step [300 / 469], Generator Loss : 3.5612621307373047, Discriminator Loss : 0.35254037380218506\n",
            "Epoch [82 / 200], Step [400 / 469], Generator Loss : 2.896533727645874, Discriminator Loss : 0.3108077347278595\n",
            "Epoch [83 / 200], Step [100 / 469], Generator Loss : 1.8152878284454346, Discriminator Loss : 0.43677520751953125\n",
            "Epoch [83 / 200], Step [200 / 469], Generator Loss : 3.2492151260375977, Discriminator Loss : 0.4046724736690521\n",
            "Epoch [83 / 200], Step [300 / 469], Generator Loss : 3.452183246612549, Discriminator Loss : 0.43279582262039185\n",
            "Epoch [83 / 200], Step [400 / 469], Generator Loss : 2.563067674636841, Discriminator Loss : 0.28124284744262695\n",
            "Epoch [84 / 200], Step [100 / 469], Generator Loss : 2.359917163848877, Discriminator Loss : 0.3605586886405945\n",
            "Epoch [84 / 200], Step [200 / 469], Generator Loss : 1.6953485012054443, Discriminator Loss : 0.43771010637283325\n",
            "Epoch [84 / 200], Step [300 / 469], Generator Loss : 2.219449043273926, Discriminator Loss : 0.37561923265457153\n",
            "Epoch [84 / 200], Step [400 / 469], Generator Loss : 1.517296314239502, Discriminator Loss : 0.5368251800537109\n",
            "Epoch [85 / 200], Step [100 / 469], Generator Loss : 2.0192949771881104, Discriminator Loss : 0.2921558618545532\n",
            "Epoch [85 / 200], Step [200 / 469], Generator Loss : 3.3292126655578613, Discriminator Loss : 0.24158388376235962\n",
            "Epoch [85 / 200], Step [300 / 469], Generator Loss : 5.712491989135742, Discriminator Loss : 0.5849819183349609\n",
            "Epoch [85 / 200], Step [400 / 469], Generator Loss : 2.464061737060547, Discriminator Loss : 0.2830505073070526\n",
            "Epoch [86 / 200], Step [100 / 469], Generator Loss : 3.173222064971924, Discriminator Loss : 0.34183186292648315\n",
            "Epoch [86 / 200], Step [200 / 469], Generator Loss : 1.9749919176101685, Discriminator Loss : 0.3745807707309723\n",
            "Epoch [86 / 200], Step [300 / 469], Generator Loss : 2.3519093990325928, Discriminator Loss : 0.2879573702812195\n",
            "Epoch [86 / 200], Step [400 / 469], Generator Loss : 2.4450221061706543, Discriminator Loss : 0.30158939957618713\n",
            "Epoch [87 / 200], Step [100 / 469], Generator Loss : 1.5668662786483765, Discriminator Loss : 0.47341471910476685\n",
            "Epoch [87 / 200], Step [200 / 469], Generator Loss : 3.4343104362487793, Discriminator Loss : 0.13101273775100708\n",
            "Epoch [87 / 200], Step [300 / 469], Generator Loss : 2.6612467765808105, Discriminator Loss : 0.2730124592781067\n",
            "Epoch [87 / 200], Step [400 / 469], Generator Loss : 4.076035976409912, Discriminator Loss : 0.4050248861312866\n",
            "Epoch [88 / 200], Step [100 / 469], Generator Loss : 1.3201559782028198, Discriminator Loss : 0.595564603805542\n",
            "Epoch [88 / 200], Step [200 / 469], Generator Loss : 1.5786056518554688, Discriminator Loss : 0.41313421726226807\n",
            "Epoch [88 / 200], Step [300 / 469], Generator Loss : 1.8562160730361938, Discriminator Loss : 0.350534051656723\n",
            "Epoch [88 / 200], Step [400 / 469], Generator Loss : 2.494842767715454, Discriminator Loss : 0.37094104290008545\n",
            "Epoch [89 / 200], Step [100 / 469], Generator Loss : 2.902621269226074, Discriminator Loss : 0.3884876072406769\n",
            "Epoch [89 / 200], Step [200 / 469], Generator Loss : 2.7262368202209473, Discriminator Loss : 0.4318813383579254\n",
            "Epoch [89 / 200], Step [300 / 469], Generator Loss : 4.248391628265381, Discriminator Loss : 0.5827006101608276\n",
            "Epoch [89 / 200], Step [400 / 469], Generator Loss : 2.0729832649230957, Discriminator Loss : 0.2434166669845581\n",
            "Epoch [90 / 200], Step [100 / 469], Generator Loss : 3.017512321472168, Discriminator Loss : 0.28138506412506104\n",
            "Epoch [90 / 200], Step [200 / 469], Generator Loss : 1.3567391633987427, Discriminator Loss : 0.45943161845207214\n",
            "Epoch [90 / 200], Step [300 / 469], Generator Loss : 1.976225733757019, Discriminator Loss : 0.3251640200614929\n",
            "Epoch [90 / 200], Step [400 / 469], Generator Loss : 1.7863645553588867, Discriminator Loss : 0.38392290472984314\n",
            "Epoch [91 / 200], Step [100 / 469], Generator Loss : 4.073968887329102, Discriminator Loss : 0.15145257115364075\n",
            "Epoch [91 / 200], Step [200 / 469], Generator Loss : 2.1745548248291016, Discriminator Loss : 0.3420301079750061\n",
            "Epoch [91 / 200], Step [300 / 469], Generator Loss : 2.866887092590332, Discriminator Loss : 0.3352707028388977\n",
            "Epoch [91 / 200], Step [400 / 469], Generator Loss : 1.4031291007995605, Discriminator Loss : 0.47078728675842285\n",
            "Epoch [92 / 200], Step [100 / 469], Generator Loss : 2.3617029190063477, Discriminator Loss : 0.29911869764328003\n",
            "Epoch [92 / 200], Step [200 / 469], Generator Loss : 3.84011173248291, Discriminator Loss : 0.5534968376159668\n",
            "Epoch [92 / 200], Step [300 / 469], Generator Loss : 2.964130401611328, Discriminator Loss : 0.3411160111427307\n",
            "Epoch [92 / 200], Step [400 / 469], Generator Loss : 2.9203431606292725, Discriminator Loss : 0.17770643532276154\n",
            "Epoch [93 / 200], Step [100 / 469], Generator Loss : 2.711820602416992, Discriminator Loss : 0.30722808837890625\n",
            "Epoch [93 / 200], Step [200 / 469], Generator Loss : 1.4091365337371826, Discriminator Loss : 0.47409000992774963\n",
            "Epoch [93 / 200], Step [300 / 469], Generator Loss : 5.569040298461914, Discriminator Loss : 0.46875131130218506\n",
            "Epoch [93 / 200], Step [400 / 469], Generator Loss : 3.0468757152557373, Discriminator Loss : 0.46112877130508423\n",
            "Epoch [94 / 200], Step [100 / 469], Generator Loss : 1.9934194087982178, Discriminator Loss : 0.4171132743358612\n",
            "Epoch [94 / 200], Step [200 / 469], Generator Loss : 2.0737690925598145, Discriminator Loss : 0.42621180415153503\n",
            "Epoch [94 / 200], Step [300 / 469], Generator Loss : 2.639190912246704, Discriminator Loss : 0.24424806237220764\n",
            "Epoch [94 / 200], Step [400 / 469], Generator Loss : 2.53830623626709, Discriminator Loss : 0.3162108063697815\n",
            "Epoch [95 / 200], Step [100 / 469], Generator Loss : 2.8929038047790527, Discriminator Loss : 0.22206580638885498\n",
            "Epoch [95 / 200], Step [200 / 469], Generator Loss : 4.220334529876709, Discriminator Loss : 0.3937152624130249\n",
            "Epoch [95 / 200], Step [300 / 469], Generator Loss : 2.1456987857818604, Discriminator Loss : 0.37259191274642944\n",
            "Epoch [95 / 200], Step [400 / 469], Generator Loss : 2.351187229156494, Discriminator Loss : 0.431524395942688\n",
            "Epoch [96 / 200], Step [100 / 469], Generator Loss : 3.2546310424804688, Discriminator Loss : 0.35845106840133667\n",
            "Epoch [96 / 200], Step [200 / 469], Generator Loss : 2.095489501953125, Discriminator Loss : 0.39737528562545776\n",
            "Epoch [96 / 200], Step [300 / 469], Generator Loss : 2.341059446334839, Discriminator Loss : 0.2093704342842102\n",
            "Epoch [96 / 200], Step [400 / 469], Generator Loss : 3.441926956176758, Discriminator Loss : 0.1322161704301834\n",
            "Epoch [97 / 200], Step [100 / 469], Generator Loss : 3.4733474254608154, Discriminator Loss : 0.4756191372871399\n",
            "Epoch [97 / 200], Step [200 / 469], Generator Loss : 1.8767597675323486, Discriminator Loss : 0.44362756609916687\n",
            "Epoch [97 / 200], Step [300 / 469], Generator Loss : 5.472727298736572, Discriminator Loss : 0.9517500996589661\n",
            "Epoch [97 / 200], Step [400 / 469], Generator Loss : 2.5673675537109375, Discriminator Loss : 0.31791266798973083\n",
            "Epoch [98 / 200], Step [100 / 469], Generator Loss : 3.067349672317505, Discriminator Loss : 0.34146738052368164\n",
            "Epoch [98 / 200], Step [200 / 469], Generator Loss : 3.429739236831665, Discriminator Loss : 0.2665502727031708\n",
            "Epoch [98 / 200], Step [300 / 469], Generator Loss : 5.270612716674805, Discriminator Loss : 0.42533448338508606\n",
            "Epoch [98 / 200], Step [400 / 469], Generator Loss : 2.0067522525787354, Discriminator Loss : 0.46940135955810547\n",
            "Epoch [99 / 200], Step [100 / 469], Generator Loss : 2.321735382080078, Discriminator Loss : 0.25003761053085327\n",
            "Epoch [99 / 200], Step [200 / 469], Generator Loss : 2.4887804985046387, Discriminator Loss : 0.20680256187915802\n",
            "Epoch [99 / 200], Step [300 / 469], Generator Loss : 2.206343412399292, Discriminator Loss : 0.39137473702430725\n",
            "Epoch [99 / 200], Step [400 / 469], Generator Loss : 2.3365535736083984, Discriminator Loss : 0.3908798098564148\n",
            "Epoch [100 / 200], Step [100 / 469], Generator Loss : 2.753355026245117, Discriminator Loss : 0.2881286144256592\n",
            "Epoch [100 / 200], Step [200 / 469], Generator Loss : 2.7286031246185303, Discriminator Loss : 0.3741573691368103\n",
            "Epoch [100 / 200], Step [300 / 469], Generator Loss : 0.9436340928077698, Discriminator Loss : 0.9303988218307495\n",
            "Epoch [100 / 200], Step [400 / 469], Generator Loss : 2.508358955383301, Discriminator Loss : 0.24616701900959015\n",
            "Epoch [101 / 200], Step [100 / 469], Generator Loss : 2.6584718227386475, Discriminator Loss : 0.25198665261268616\n",
            "Epoch [101 / 200], Step [200 / 469], Generator Loss : 2.8893816471099854, Discriminator Loss : 0.41732358932495117\n",
            "Epoch [101 / 200], Step [300 / 469], Generator Loss : 2.3330013751983643, Discriminator Loss : 0.29684925079345703\n",
            "Epoch [101 / 200], Step [400 / 469], Generator Loss : 2.2377753257751465, Discriminator Loss : 0.3457643389701843\n",
            "Epoch [102 / 200], Step [100 / 469], Generator Loss : 2.539073944091797, Discriminator Loss : 0.2894873023033142\n",
            "Epoch [102 / 200], Step [200 / 469], Generator Loss : 3.680715560913086, Discriminator Loss : 0.21879999339580536\n",
            "Epoch [102 / 200], Step [300 / 469], Generator Loss : 3.4756546020507812, Discriminator Loss : 0.35648787021636963\n",
            "Epoch [102 / 200], Step [400 / 469], Generator Loss : 2.033935070037842, Discriminator Loss : 0.37830257415771484\n",
            "Epoch [103 / 200], Step [100 / 469], Generator Loss : 3.0991437435150146, Discriminator Loss : 0.2813495397567749\n",
            "Epoch [103 / 200], Step [200 / 469], Generator Loss : 2.3144540786743164, Discriminator Loss : 0.2505229711532593\n",
            "Epoch [103 / 200], Step [300 / 469], Generator Loss : 1.9339025020599365, Discriminator Loss : 0.3625737428665161\n",
            "Epoch [103 / 200], Step [400 / 469], Generator Loss : 3.044346332550049, Discriminator Loss : 0.45177358388900757\n",
            "Epoch [104 / 200], Step [100 / 469], Generator Loss : 1.840080738067627, Discriminator Loss : 0.45651206374168396\n",
            "Epoch [104 / 200], Step [200 / 469], Generator Loss : 2.5190396308898926, Discriminator Loss : 0.31581345200538635\n",
            "Epoch [104 / 200], Step [300 / 469], Generator Loss : 1.2197173833847046, Discriminator Loss : 0.6936696767807007\n",
            "Epoch [104 / 200], Step [400 / 469], Generator Loss : 3.093069076538086, Discriminator Loss : 0.3457103371620178\n",
            "Epoch [105 / 200], Step [100 / 469], Generator Loss : 2.9109296798706055, Discriminator Loss : 0.367531418800354\n",
            "Epoch [105 / 200], Step [200 / 469], Generator Loss : 3.9621543884277344, Discriminator Loss : 0.4426356256008148\n",
            "Epoch [105 / 200], Step [300 / 469], Generator Loss : 2.55186128616333, Discriminator Loss : 0.5478365421295166\n",
            "Epoch [105 / 200], Step [400 / 469], Generator Loss : 5.932010173797607, Discriminator Loss : 0.8285824060440063\n",
            "Epoch [106 / 200], Step [100 / 469], Generator Loss : 3.623663902282715, Discriminator Loss : 0.49502184987068176\n",
            "Epoch [106 / 200], Step [200 / 469], Generator Loss : 1.8738462924957275, Discriminator Loss : 0.33325326442718506\n",
            "Epoch [106 / 200], Step [300 / 469], Generator Loss : 2.144747734069824, Discriminator Loss : 0.3754463195800781\n",
            "Epoch [106 / 200], Step [400 / 469], Generator Loss : 1.7667361497879028, Discriminator Loss : 0.4195077419281006\n",
            "Epoch [107 / 200], Step [100 / 469], Generator Loss : 3.024136543273926, Discriminator Loss : 0.32264795899391174\n",
            "Epoch [107 / 200], Step [200 / 469], Generator Loss : 3.5891072750091553, Discriminator Loss : 0.45069122314453125\n",
            "Epoch [107 / 200], Step [300 / 469], Generator Loss : 2.199319362640381, Discriminator Loss : 0.31964391469955444\n",
            "Epoch [107 / 200], Step [400 / 469], Generator Loss : 3.479861259460449, Discriminator Loss : 0.43719738721847534\n",
            "Epoch [108 / 200], Step [100 / 469], Generator Loss : 2.3329286575317383, Discriminator Loss : 0.28993916511535645\n",
            "Epoch [108 / 200], Step [200 / 469], Generator Loss : 3.738910675048828, Discriminator Loss : 0.3801923394203186\n",
            "Epoch [108 / 200], Step [300 / 469], Generator Loss : 2.5015439987182617, Discriminator Loss : 0.2922961115837097\n",
            "Epoch [108 / 200], Step [400 / 469], Generator Loss : 2.098954200744629, Discriminator Loss : 0.33470189571380615\n",
            "Epoch [109 / 200], Step [100 / 469], Generator Loss : 3.9329333305358887, Discriminator Loss : 0.32414284348487854\n",
            "Epoch [109 / 200], Step [200 / 469], Generator Loss : 2.180619478225708, Discriminator Loss : 0.38318005204200745\n",
            "Epoch [109 / 200], Step [300 / 469], Generator Loss : 2.0885486602783203, Discriminator Loss : 0.2392362654209137\n",
            "Epoch [109 / 200], Step [400 / 469], Generator Loss : 2.520946979522705, Discriminator Loss : 0.36886411905288696\n",
            "Epoch [110 / 200], Step [100 / 469], Generator Loss : 2.6211795806884766, Discriminator Loss : 0.1694646179676056\n",
            "Epoch [110 / 200], Step [200 / 469], Generator Loss : 2.800305128097534, Discriminator Loss : 0.4398164749145508\n",
            "Epoch [110 / 200], Step [300 / 469], Generator Loss : 3.8259198665618896, Discriminator Loss : 0.49526363611221313\n",
            "Epoch [110 / 200], Step [400 / 469], Generator Loss : 2.227773666381836, Discriminator Loss : 0.5555852651596069\n",
            "Epoch [111 / 200], Step [100 / 469], Generator Loss : 3.981893301010132, Discriminator Loss : 0.5988562107086182\n",
            "Epoch [111 / 200], Step [200 / 469], Generator Loss : 2.3642916679382324, Discriminator Loss : 0.28132832050323486\n",
            "Epoch [111 / 200], Step [300 / 469], Generator Loss : 2.6835432052612305, Discriminator Loss : 0.26066362857818604\n",
            "Epoch [111 / 200], Step [400 / 469], Generator Loss : 3.2242627143859863, Discriminator Loss : 0.24105428159236908\n",
            "Epoch [112 / 200], Step [100 / 469], Generator Loss : 2.6403894424438477, Discriminator Loss : 0.318496435880661\n",
            "Epoch [112 / 200], Step [200 / 469], Generator Loss : 2.9307217597961426, Discriminator Loss : 0.1319567710161209\n",
            "Epoch [112 / 200], Step [300 / 469], Generator Loss : 4.425144195556641, Discriminator Loss : 0.3199724853038788\n",
            "Epoch [112 / 200], Step [400 / 469], Generator Loss : 2.0217857360839844, Discriminator Loss : 0.2934103012084961\n",
            "Epoch [113 / 200], Step [100 / 469], Generator Loss : 4.037474155426025, Discriminator Loss : 0.3320290744304657\n",
            "Epoch [113 / 200], Step [200 / 469], Generator Loss : 3.2049431800842285, Discriminator Loss : 0.19387343525886536\n",
            "Epoch [113 / 200], Step [300 / 469], Generator Loss : 4.896181106567383, Discriminator Loss : 0.6094149947166443\n",
            "Epoch [113 / 200], Step [400 / 469], Generator Loss : 1.7175387144088745, Discriminator Loss : 0.36754366755485535\n",
            "Epoch [114 / 200], Step [100 / 469], Generator Loss : 3.3881940841674805, Discriminator Loss : 0.28710493445396423\n",
            "Epoch [114 / 200], Step [200 / 469], Generator Loss : 2.227332830429077, Discriminator Loss : 0.3207678198814392\n",
            "Epoch [114 / 200], Step [300 / 469], Generator Loss : 3.2262120246887207, Discriminator Loss : 0.24761338531970978\n",
            "Epoch [114 / 200], Step [400 / 469], Generator Loss : 2.821207046508789, Discriminator Loss : 0.3928556442260742\n",
            "Epoch [115 / 200], Step [100 / 469], Generator Loss : 1.5979194641113281, Discriminator Loss : 0.385032594203949\n",
            "Epoch [115 / 200], Step [200 / 469], Generator Loss : 7.013385772705078, Discriminator Loss : 1.1783111095428467\n",
            "Epoch [115 / 200], Step [300 / 469], Generator Loss : 0.41958263516426086, Discriminator Loss : 1.359073519706726\n",
            "Epoch [115 / 200], Step [400 / 469], Generator Loss : 2.893045425415039, Discriminator Loss : 0.2883092761039734\n",
            "Epoch [116 / 200], Step [100 / 469], Generator Loss : 3.165611982345581, Discriminator Loss : 0.23958173394203186\n",
            "Epoch [116 / 200], Step [200 / 469], Generator Loss : 4.503807544708252, Discriminator Loss : 0.4933127164840698\n",
            "Epoch [116 / 200], Step [300 / 469], Generator Loss : 2.820124626159668, Discriminator Loss : 0.37687087059020996\n",
            "Epoch [116 / 200], Step [400 / 469], Generator Loss : 3.0195679664611816, Discriminator Loss : 0.36216622591018677\n",
            "Epoch [117 / 200], Step [100 / 469], Generator Loss : 3.779752731323242, Discriminator Loss : 0.3762359619140625\n",
            "Epoch [117 / 200], Step [200 / 469], Generator Loss : 2.797159194946289, Discriminator Loss : 0.2697351574897766\n",
            "Epoch [117 / 200], Step [300 / 469], Generator Loss : 2.5632171630859375, Discriminator Loss : 0.2490198314189911\n",
            "Epoch [117 / 200], Step [400 / 469], Generator Loss : 2.0458221435546875, Discriminator Loss : 0.342756986618042\n",
            "Epoch [118 / 200], Step [100 / 469], Generator Loss : 3.0081229209899902, Discriminator Loss : 0.21475186944007874\n",
            "Epoch [118 / 200], Step [200 / 469], Generator Loss : 5.224310874938965, Discriminator Loss : 0.48671671748161316\n",
            "Epoch [118 / 200], Step [300 / 469], Generator Loss : 4.032065391540527, Discriminator Loss : 0.39522433280944824\n",
            "Epoch [118 / 200], Step [400 / 469], Generator Loss : 3.3163812160491943, Discriminator Loss : 0.31543752551078796\n",
            "Epoch [119 / 200], Step [100 / 469], Generator Loss : 2.302764892578125, Discriminator Loss : 0.31570589542388916\n",
            "Epoch [119 / 200], Step [200 / 469], Generator Loss : 2.2378878593444824, Discriminator Loss : 0.3737078309059143\n",
            "Epoch [119 / 200], Step [300 / 469], Generator Loss : 2.6180527210235596, Discriminator Loss : 0.36988717317581177\n",
            "Epoch [119 / 200], Step [400 / 469], Generator Loss : 4.1792402267456055, Discriminator Loss : 0.7001473903656006\n",
            "Epoch [120 / 200], Step [100 / 469], Generator Loss : 5.097172260284424, Discriminator Loss : 0.4593801498413086\n",
            "Epoch [120 / 200], Step [200 / 469], Generator Loss : 3.00752854347229, Discriminator Loss : 0.48685193061828613\n",
            "Epoch [120 / 200], Step [300 / 469], Generator Loss : 1.8731098175048828, Discriminator Loss : 0.41466450691223145\n",
            "Epoch [120 / 200], Step [400 / 469], Generator Loss : 1.6107487678527832, Discriminator Loss : 0.5192537307739258\n",
            "Epoch [121 / 200], Step [100 / 469], Generator Loss : 3.019667625427246, Discriminator Loss : 0.16899481415748596\n",
            "Epoch [121 / 200], Step [200 / 469], Generator Loss : 2.839993953704834, Discriminator Loss : 0.4309901297092438\n",
            "Epoch [121 / 200], Step [300 / 469], Generator Loss : 2.715437412261963, Discriminator Loss : 0.36285340785980225\n",
            "Epoch [121 / 200], Step [400 / 469], Generator Loss : 4.344058990478516, Discriminator Loss : 0.3311600089073181\n",
            "Epoch [122 / 200], Step [100 / 469], Generator Loss : 1.7341341972351074, Discriminator Loss : 0.38090160489082336\n",
            "Epoch [122 / 200], Step [200 / 469], Generator Loss : 1.669558048248291, Discriminator Loss : 0.5529583692550659\n",
            "Epoch [122 / 200], Step [300 / 469], Generator Loss : 2.1559348106384277, Discriminator Loss : 0.3752065896987915\n",
            "Epoch [122 / 200], Step [400 / 469], Generator Loss : 3.640939474105835, Discriminator Loss : 0.5301427841186523\n",
            "Epoch [123 / 200], Step [100 / 469], Generator Loss : 5.359491348266602, Discriminator Loss : 0.4898320734500885\n",
            "Epoch [123 / 200], Step [200 / 469], Generator Loss : 6.270651817321777, Discriminator Loss : 0.8674517869949341\n",
            "Epoch [123 / 200], Step [300 / 469], Generator Loss : 2.251791477203369, Discriminator Loss : 0.29882264137268066\n",
            "Epoch [123 / 200], Step [400 / 469], Generator Loss : 3.3277816772460938, Discriminator Loss : 0.2568083107471466\n",
            "Epoch [124 / 200], Step [100 / 469], Generator Loss : 3.7172365188598633, Discriminator Loss : 0.19267405569553375\n",
            "Epoch [124 / 200], Step [200 / 469], Generator Loss : 2.708498477935791, Discriminator Loss : 0.2644127309322357\n",
            "Epoch [124 / 200], Step [300 / 469], Generator Loss : 1.798053503036499, Discriminator Loss : 0.548166036605835\n",
            "Epoch [124 / 200], Step [400 / 469], Generator Loss : 3.268340587615967, Discriminator Loss : 0.22178494930267334\n",
            "Epoch [125 / 200], Step [100 / 469], Generator Loss : 3.114151954650879, Discriminator Loss : 0.1418425440788269\n",
            "Epoch [125 / 200], Step [200 / 469], Generator Loss : 2.633697986602783, Discriminator Loss : 0.2953585386276245\n",
            "Epoch [125 / 200], Step [300 / 469], Generator Loss : 3.744009256362915, Discriminator Loss : 0.1522393524646759\n",
            "Epoch [125 / 200], Step [400 / 469], Generator Loss : 3.1073825359344482, Discriminator Loss : 0.29482534527778625\n",
            "Epoch [126 / 200], Step [100 / 469], Generator Loss : 4.462975025177002, Discriminator Loss : 0.34981703758239746\n",
            "Epoch [126 / 200], Step [200 / 469], Generator Loss : 2.3676035404205322, Discriminator Loss : 0.355899453163147\n",
            "Epoch [126 / 200], Step [300 / 469], Generator Loss : 4.133914947509766, Discriminator Loss : 0.2478104829788208\n",
            "Epoch [126 / 200], Step [400 / 469], Generator Loss : 3.2712621688842773, Discriminator Loss : 0.23562677204608917\n",
            "Epoch [127 / 200], Step [100 / 469], Generator Loss : 3.0285377502441406, Discriminator Loss : 0.29267269372940063\n",
            "Epoch [127 / 200], Step [200 / 469], Generator Loss : 3.2238073348999023, Discriminator Loss : 0.2211533486843109\n",
            "Epoch [127 / 200], Step [300 / 469], Generator Loss : 3.838700294494629, Discriminator Loss : 0.5334967374801636\n",
            "Epoch [127 / 200], Step [400 / 469], Generator Loss : 2.4804654121398926, Discriminator Loss : 0.3931840658187866\n",
            "Epoch [128 / 200], Step [100 / 469], Generator Loss : 1.723861575126648, Discriminator Loss : 0.40732502937316895\n",
            "Epoch [128 / 200], Step [200 / 469], Generator Loss : 2.8097596168518066, Discriminator Loss : 0.25274425745010376\n",
            "Epoch [128 / 200], Step [300 / 469], Generator Loss : 1.9320738315582275, Discriminator Loss : 0.2717324495315552\n",
            "Epoch [128 / 200], Step [400 / 469], Generator Loss : 1.7111196517944336, Discriminator Loss : 0.3534945249557495\n",
            "Epoch [129 / 200], Step [100 / 469], Generator Loss : 3.014943838119507, Discriminator Loss : 0.4570542275905609\n",
            "Epoch [129 / 200], Step [200 / 469], Generator Loss : 1.8077921867370605, Discriminator Loss : 0.40382957458496094\n",
            "Epoch [129 / 200], Step [300 / 469], Generator Loss : 5.922393798828125, Discriminator Loss : 0.5537551045417786\n",
            "Epoch [129 / 200], Step [400 / 469], Generator Loss : 2.637281656265259, Discriminator Loss : 0.42264652252197266\n",
            "Epoch [130 / 200], Step [100 / 469], Generator Loss : 3.2131800651550293, Discriminator Loss : 0.2819157838821411\n",
            "Epoch [130 / 200], Step [200 / 469], Generator Loss : 3.2988767623901367, Discriminator Loss : 0.18439331650733948\n",
            "Epoch [130 / 200], Step [300 / 469], Generator Loss : 6.617981910705566, Discriminator Loss : 0.7419764399528503\n",
            "Epoch [130 / 200], Step [400 / 469], Generator Loss : 2.8756589889526367, Discriminator Loss : 0.21003730595111847\n",
            "Epoch [131 / 200], Step [100 / 469], Generator Loss : 0.9029704332351685, Discriminator Loss : 0.9895859956741333\n",
            "Epoch [131 / 200], Step [200 / 469], Generator Loss : 2.313206434249878, Discriminator Loss : 0.39487627148628235\n",
            "Epoch [131 / 200], Step [300 / 469], Generator Loss : 1.8469212055206299, Discriminator Loss : 0.4455033540725708\n",
            "Epoch [131 / 200], Step [400 / 469], Generator Loss : 2.662785053253174, Discriminator Loss : 0.2909121513366699\n",
            "Epoch [132 / 200], Step [100 / 469], Generator Loss : 4.338710784912109, Discriminator Loss : 0.4029271602630615\n",
            "Epoch [132 / 200], Step [200 / 469], Generator Loss : 5.161221981048584, Discriminator Loss : 0.5948138236999512\n",
            "Epoch [132 / 200], Step [300 / 469], Generator Loss : 2.7383742332458496, Discriminator Loss : 0.24249857664108276\n",
            "Epoch [132 / 200], Step [400 / 469], Generator Loss : 3.5381274223327637, Discriminator Loss : 0.46347475051879883\n",
            "Epoch [133 / 200], Step [100 / 469], Generator Loss : 3.5870728492736816, Discriminator Loss : 0.19444623589515686\n",
            "Epoch [133 / 200], Step [200 / 469], Generator Loss : 2.291963815689087, Discriminator Loss : 0.31177037954330444\n",
            "Epoch [133 / 200], Step [300 / 469], Generator Loss : 2.1948275566101074, Discriminator Loss : 0.3237537145614624\n",
            "Epoch [133 / 200], Step [400 / 469], Generator Loss : 4.086740970611572, Discriminator Loss : 0.17954981327056885\n",
            "Epoch [134 / 200], Step [100 / 469], Generator Loss : 2.459148406982422, Discriminator Loss : 0.2979840636253357\n",
            "Epoch [134 / 200], Step [200 / 469], Generator Loss : 3.072493314743042, Discriminator Loss : 0.31448686122894287\n",
            "Epoch [134 / 200], Step [300 / 469], Generator Loss : 2.176236152648926, Discriminator Loss : 0.2790372371673584\n",
            "Epoch [134 / 200], Step [400 / 469], Generator Loss : 1.8005993366241455, Discriminator Loss : 0.37767407298088074\n",
            "Epoch [135 / 200], Step [100 / 469], Generator Loss : 2.864837169647217, Discriminator Loss : 0.47696083784103394\n",
            "Epoch [135 / 200], Step [200 / 469], Generator Loss : 0.8112323880195618, Discriminator Loss : 0.8686346411705017\n",
            "Epoch [135 / 200], Step [300 / 469], Generator Loss : 1.8270798921585083, Discriminator Loss : 0.6280597448348999\n",
            "Epoch [135 / 200], Step [400 / 469], Generator Loss : 3.3624215126037598, Discriminator Loss : 0.37808680534362793\n",
            "Epoch [136 / 200], Step [100 / 469], Generator Loss : 3.728095293045044, Discriminator Loss : 0.25674670934677124\n",
            "Epoch [136 / 200], Step [200 / 469], Generator Loss : 1.6490534543991089, Discriminator Loss : 0.5504513382911682\n",
            "Epoch [136 / 200], Step [300 / 469], Generator Loss : 2.4691009521484375, Discriminator Loss : 0.35500818490982056\n",
            "Epoch [136 / 200], Step [400 / 469], Generator Loss : 1.569408893585205, Discriminator Loss : 0.46009254455566406\n",
            "Epoch [137 / 200], Step [100 / 469], Generator Loss : 2.135632038116455, Discriminator Loss : 0.27530092000961304\n",
            "Epoch [137 / 200], Step [200 / 469], Generator Loss : 2.484004020690918, Discriminator Loss : 0.3207241892814636\n",
            "Epoch [137 / 200], Step [300 / 469], Generator Loss : 2.3691861629486084, Discriminator Loss : 0.40472105145454407\n",
            "Epoch [137 / 200], Step [400 / 469], Generator Loss : 3.0518698692321777, Discriminator Loss : 0.25108417868614197\n",
            "Epoch [138 / 200], Step [100 / 469], Generator Loss : 1.7191400527954102, Discriminator Loss : 0.4556727111339569\n",
            "Epoch [138 / 200], Step [200 / 469], Generator Loss : 2.8501996994018555, Discriminator Loss : 0.1747797131538391\n",
            "Epoch [138 / 200], Step [300 / 469], Generator Loss : 3.211806535720825, Discriminator Loss : 0.2953299283981323\n",
            "Epoch [138 / 200], Step [400 / 469], Generator Loss : 3.1403722763061523, Discriminator Loss : 0.14368775486946106\n",
            "Epoch [139 / 200], Step [100 / 469], Generator Loss : 1.9072027206420898, Discriminator Loss : 0.37800177931785583\n",
            "Epoch [139 / 200], Step [200 / 469], Generator Loss : 2.317579746246338, Discriminator Loss : 0.5348069667816162\n",
            "Epoch [139 / 200], Step [300 / 469], Generator Loss : 5.851768970489502, Discriminator Loss : 0.36095666885375977\n",
            "Epoch [139 / 200], Step [400 / 469], Generator Loss : 2.090222120285034, Discriminator Loss : 0.34663206338882446\n",
            "Epoch [140 / 200], Step [100 / 469], Generator Loss : 2.4492416381835938, Discriminator Loss : 0.3114071190357208\n",
            "Epoch [140 / 200], Step [200 / 469], Generator Loss : 2.1080024242401123, Discriminator Loss : 0.357374370098114\n",
            "Epoch [140 / 200], Step [300 / 469], Generator Loss : 3.373673439025879, Discriminator Loss : 0.20182576775550842\n",
            "Epoch [140 / 200], Step [400 / 469], Generator Loss : 3.7816874980926514, Discriminator Loss : 0.38626471161842346\n",
            "Epoch [141 / 200], Step [100 / 469], Generator Loss : 3.905538558959961, Discriminator Loss : 0.2763402462005615\n",
            "Epoch [141 / 200], Step [200 / 469], Generator Loss : 2.5557785034179688, Discriminator Loss : 0.19433480501174927\n",
            "Epoch [141 / 200], Step [300 / 469], Generator Loss : 2.6518845558166504, Discriminator Loss : 0.2710532546043396\n",
            "Epoch [141 / 200], Step [400 / 469], Generator Loss : 2.7428526878356934, Discriminator Loss : 0.2562653422355652\n",
            "Epoch [142 / 200], Step [100 / 469], Generator Loss : 3.6165637969970703, Discriminator Loss : 0.22694890201091766\n",
            "Epoch [142 / 200], Step [200 / 469], Generator Loss : 3.3452138900756836, Discriminator Loss : 0.26477259397506714\n",
            "Epoch [142 / 200], Step [300 / 469], Generator Loss : 2.813884735107422, Discriminator Loss : 0.1468074917793274\n",
            "Epoch [142 / 200], Step [400 / 469], Generator Loss : 3.0716378688812256, Discriminator Loss : 0.1952618658542633\n",
            "Epoch [143 / 200], Step [100 / 469], Generator Loss : 2.627924680709839, Discriminator Loss : 0.2707247734069824\n",
            "Epoch [143 / 200], Step [200 / 469], Generator Loss : 2.9437332153320312, Discriminator Loss : 0.30290064215660095\n",
            "Epoch [143 / 200], Step [300 / 469], Generator Loss : 3.5992705821990967, Discriminator Loss : 0.2959747314453125\n",
            "Epoch [143 / 200], Step [400 / 469], Generator Loss : 2.7723946571350098, Discriminator Loss : 0.26460933685302734\n",
            "Epoch [144 / 200], Step [100 / 469], Generator Loss : 1.972977638244629, Discriminator Loss : 0.3883243203163147\n",
            "Epoch [144 / 200], Step [200 / 469], Generator Loss : 5.359053611755371, Discriminator Loss : 0.6671141982078552\n",
            "Epoch [144 / 200], Step [300 / 469], Generator Loss : 6.917665958404541, Discriminator Loss : 0.9123876690864563\n",
            "Epoch [144 / 200], Step [400 / 469], Generator Loss : 2.274491786956787, Discriminator Loss : 0.3691447377204895\n",
            "Epoch [145 / 200], Step [100 / 469], Generator Loss : 2.6971566677093506, Discriminator Loss : 0.23393024504184723\n",
            "Epoch [145 / 200], Step [200 / 469], Generator Loss : 2.7250113487243652, Discriminator Loss : 0.3981444835662842\n",
            "Epoch [145 / 200], Step [300 / 469], Generator Loss : 2.1915202140808105, Discriminator Loss : 0.5475502014160156\n",
            "Epoch [145 / 200], Step [400 / 469], Generator Loss : 2.5555295944213867, Discriminator Loss : 0.25348079204559326\n",
            "Epoch [146 / 200], Step [100 / 469], Generator Loss : 3.1384501457214355, Discriminator Loss : 0.22054293751716614\n",
            "Epoch [146 / 200], Step [200 / 469], Generator Loss : 6.808802604675293, Discriminator Loss : 0.6516758799552917\n",
            "Epoch [146 / 200], Step [300 / 469], Generator Loss : 3.0070371627807617, Discriminator Loss : 0.3416425585746765\n",
            "Epoch [146 / 200], Step [400 / 469], Generator Loss : 2.0015335083007812, Discriminator Loss : 0.6143423914909363\n",
            "Epoch [147 / 200], Step [100 / 469], Generator Loss : 3.3074567317962646, Discriminator Loss : 0.2549044191837311\n",
            "Epoch [147 / 200], Step [200 / 469], Generator Loss : 3.3498950004577637, Discriminator Loss : 0.22712448239326477\n",
            "Epoch [147 / 200], Step [300 / 469], Generator Loss : 2.596111297607422, Discriminator Loss : 0.4664889872074127\n",
            "Epoch [147 / 200], Step [400 / 469], Generator Loss : 1.7681734561920166, Discriminator Loss : 0.4026678800582886\n",
            "Epoch [148 / 200], Step [100 / 469], Generator Loss : 2.78230357170105, Discriminator Loss : 0.21631567180156708\n",
            "Epoch [148 / 200], Step [200 / 469], Generator Loss : 2.0894405841827393, Discriminator Loss : 0.3201393485069275\n",
            "Epoch [148 / 200], Step [300 / 469], Generator Loss : 2.951026439666748, Discriminator Loss : 0.3619737923145294\n",
            "Epoch [148 / 200], Step [400 / 469], Generator Loss : 2.259798765182495, Discriminator Loss : 0.44040626287460327\n",
            "Epoch [149 / 200], Step [100 / 469], Generator Loss : 5.595762729644775, Discriminator Loss : 0.6938305497169495\n",
            "Epoch [149 / 200], Step [200 / 469], Generator Loss : 2.7295985221862793, Discriminator Loss : 0.2927793860435486\n",
            "Epoch [149 / 200], Step [300 / 469], Generator Loss : 2.159893035888672, Discriminator Loss : 0.22457459568977356\n",
            "Epoch [149 / 200], Step [400 / 469], Generator Loss : 2.225616455078125, Discriminator Loss : 0.28477731347084045\n",
            "Epoch [150 / 200], Step [100 / 469], Generator Loss : 5.338685035705566, Discriminator Loss : 0.4650535583496094\n",
            "Epoch [150 / 200], Step [200 / 469], Generator Loss : 3.374135971069336, Discriminator Loss : 0.21090613305568695\n",
            "Epoch [150 / 200], Step [300 / 469], Generator Loss : 4.011209964752197, Discriminator Loss : 0.5918155908584595\n",
            "Epoch [150 / 200], Step [400 / 469], Generator Loss : 4.0664215087890625, Discriminator Loss : 0.1805766224861145\n",
            "Epoch [151 / 200], Step [100 / 469], Generator Loss : 2.2877466678619385, Discriminator Loss : 0.35723966360092163\n",
            "Epoch [151 / 200], Step [200 / 469], Generator Loss : 2.169196367263794, Discriminator Loss : 0.40366315841674805\n",
            "Epoch [151 / 200], Step [300 / 469], Generator Loss : 2.0983731746673584, Discriminator Loss : 0.3659152388572693\n",
            "Epoch [151 / 200], Step [400 / 469], Generator Loss : 4.030546188354492, Discriminator Loss : 0.2596694827079773\n",
            "Epoch [152 / 200], Step [100 / 469], Generator Loss : 1.3234822750091553, Discriminator Loss : 0.622575044631958\n",
            "Epoch [152 / 200], Step [200 / 469], Generator Loss : 3.012737989425659, Discriminator Loss : 0.4261477291584015\n",
            "Epoch [152 / 200], Step [300 / 469], Generator Loss : 2.30647873878479, Discriminator Loss : 0.19839239120483398\n",
            "Epoch [152 / 200], Step [400 / 469], Generator Loss : 4.404311656951904, Discriminator Loss : 0.39617201685905457\n",
            "Epoch [153 / 200], Step [100 / 469], Generator Loss : 3.0966908931732178, Discriminator Loss : 0.17005066573619843\n",
            "Epoch [153 / 200], Step [200 / 469], Generator Loss : 2.7051162719726562, Discriminator Loss : 0.23777207732200623\n",
            "Epoch [153 / 200], Step [300 / 469], Generator Loss : 1.83504319190979, Discriminator Loss : 0.4653317332267761\n",
            "Epoch [153 / 200], Step [400 / 469], Generator Loss : 2.4351398944854736, Discriminator Loss : 0.2574445605278015\n",
            "Epoch [154 / 200], Step [100 / 469], Generator Loss : 4.738699913024902, Discriminator Loss : 0.6177399158477783\n",
            "Epoch [154 / 200], Step [200 / 469], Generator Loss : 2.9042482376098633, Discriminator Loss : 0.159013569355011\n",
            "Epoch [154 / 200], Step [300 / 469], Generator Loss : 3.084808349609375, Discriminator Loss : 0.29123082756996155\n",
            "Epoch [154 / 200], Step [400 / 469], Generator Loss : 2.105156660079956, Discriminator Loss : 0.2975557744503021\n",
            "Epoch [155 / 200], Step [100 / 469], Generator Loss : 3.988919496536255, Discriminator Loss : 0.31881535053253174\n",
            "Epoch [155 / 200], Step [200 / 469], Generator Loss : 2.3887460231781006, Discriminator Loss : 0.32108280062675476\n",
            "Epoch [155 / 200], Step [300 / 469], Generator Loss : 3.061722993850708, Discriminator Loss : 0.3403436243534088\n",
            "Epoch [155 / 200], Step [400 / 469], Generator Loss : 2.6503007411956787, Discriminator Loss : 0.4127986431121826\n",
            "Epoch [156 / 200], Step [100 / 469], Generator Loss : 2.035499095916748, Discriminator Loss : 0.6341152787208557\n",
            "Epoch [156 / 200], Step [200 / 469], Generator Loss : 3.99961256980896, Discriminator Loss : 0.19413639605045319\n",
            "Epoch [156 / 200], Step [300 / 469], Generator Loss : 3.0582118034362793, Discriminator Loss : 0.27250224351882935\n",
            "Epoch [156 / 200], Step [400 / 469], Generator Loss : 3.21420955657959, Discriminator Loss : 0.2561783790588379\n",
            "Epoch [157 / 200], Step [100 / 469], Generator Loss : 2.7054970264434814, Discriminator Loss : 0.23170028626918793\n",
            "Epoch [157 / 200], Step [200 / 469], Generator Loss : 2.8459231853485107, Discriminator Loss : 0.25424349308013916\n",
            "Epoch [157 / 200], Step [300 / 469], Generator Loss : 2.7043027877807617, Discriminator Loss : 0.2874091863632202\n",
            "Epoch [157 / 200], Step [400 / 469], Generator Loss : 2.5834200382232666, Discriminator Loss : 0.37224483489990234\n",
            "Epoch [158 / 200], Step [100 / 469], Generator Loss : 3.5613300800323486, Discriminator Loss : 0.43096721172332764\n",
            "Epoch [158 / 200], Step [200 / 469], Generator Loss : 2.766770362854004, Discriminator Loss : 0.22942808270454407\n",
            "Epoch [158 / 200], Step [300 / 469], Generator Loss : 1.4664506912231445, Discriminator Loss : 0.5649810433387756\n",
            "Epoch [158 / 200], Step [400 / 469], Generator Loss : 2.594326972961426, Discriminator Loss : 0.2888193130493164\n",
            "Epoch [159 / 200], Step [100 / 469], Generator Loss : 4.413491249084473, Discriminator Loss : 0.29255789518356323\n",
            "Epoch [159 / 200], Step [200 / 469], Generator Loss : 2.333008289337158, Discriminator Loss : 0.25587716698646545\n",
            "Epoch [159 / 200], Step [300 / 469], Generator Loss : 2.8730902671813965, Discriminator Loss : 0.3310425877571106\n",
            "Epoch [159 / 200], Step [400 / 469], Generator Loss : 3.3202810287475586, Discriminator Loss : 0.19620653986930847\n",
            "Epoch [160 / 200], Step [100 / 469], Generator Loss : 4.2648701667785645, Discriminator Loss : 0.38164305686950684\n",
            "Epoch [160 / 200], Step [200 / 469], Generator Loss : 3.2820210456848145, Discriminator Loss : 0.407461941242218\n",
            "Epoch [160 / 200], Step [300 / 469], Generator Loss : 3.3943920135498047, Discriminator Loss : 0.16311369836330414\n",
            "Epoch [160 / 200], Step [400 / 469], Generator Loss : 2.2225303649902344, Discriminator Loss : 0.30850082635879517\n",
            "Epoch [161 / 200], Step [100 / 469], Generator Loss : 3.967928886413574, Discriminator Loss : 0.1948125958442688\n",
            "Epoch [161 / 200], Step [200 / 469], Generator Loss : 4.373008728027344, Discriminator Loss : 0.16221284866333008\n",
            "Epoch [161 / 200], Step [300 / 469], Generator Loss : 6.53762149810791, Discriminator Loss : 0.9135846495628357\n",
            "Epoch [161 / 200], Step [400 / 469], Generator Loss : 2.562610149383545, Discriminator Loss : 0.3421141505241394\n",
            "Epoch [162 / 200], Step [100 / 469], Generator Loss : 4.847810745239258, Discriminator Loss : 0.7071911096572876\n",
            "Epoch [162 / 200], Step [200 / 469], Generator Loss : 2.5489134788513184, Discriminator Loss : 0.2685597538948059\n",
            "Epoch [162 / 200], Step [300 / 469], Generator Loss : 3.3283257484436035, Discriminator Loss : 0.16872140765190125\n",
            "Epoch [162 / 200], Step [400 / 469], Generator Loss : 3.756697177886963, Discriminator Loss : 0.24567320942878723\n",
            "Epoch [163 / 200], Step [100 / 469], Generator Loss : 1.5899182558059692, Discriminator Loss : 0.39662283658981323\n",
            "Epoch [163 / 200], Step [200 / 469], Generator Loss : 5.519598007202148, Discriminator Loss : 0.46712520718574524\n",
            "Epoch [163 / 200], Step [300 / 469], Generator Loss : 1.6738049983978271, Discriminator Loss : 0.4306918978691101\n",
            "Epoch [163 / 200], Step [400 / 469], Generator Loss : 2.1086597442626953, Discriminator Loss : 0.3440166115760803\n",
            "Epoch [164 / 200], Step [100 / 469], Generator Loss : 1.9524763822555542, Discriminator Loss : 0.3402445316314697\n",
            "Epoch [164 / 200], Step [200 / 469], Generator Loss : 2.7496337890625, Discriminator Loss : 0.3011625111103058\n",
            "Epoch [164 / 200], Step [300 / 469], Generator Loss : 2.0471930503845215, Discriminator Loss : 0.3450417220592499\n",
            "Epoch [164 / 200], Step [400 / 469], Generator Loss : 3.3571383953094482, Discriminator Loss : 0.2974402606487274\n",
            "Epoch [165 / 200], Step [100 / 469], Generator Loss : 2.7075281143188477, Discriminator Loss : 0.40270835161209106\n",
            "Epoch [165 / 200], Step [200 / 469], Generator Loss : 3.1802210807800293, Discriminator Loss : 0.35920798778533936\n",
            "Epoch [165 / 200], Step [300 / 469], Generator Loss : 3.578122854232788, Discriminator Loss : 0.3845849633216858\n",
            "Epoch [165 / 200], Step [400 / 469], Generator Loss : 4.671319961547852, Discriminator Loss : 0.5007805824279785\n",
            "Epoch [166 / 200], Step [100 / 469], Generator Loss : 2.5203568935394287, Discriminator Loss : 0.30272573232650757\n",
            "Epoch [166 / 200], Step [200 / 469], Generator Loss : 3.784172773361206, Discriminator Loss : 0.7328483462333679\n",
            "Epoch [166 / 200], Step [300 / 469], Generator Loss : 2.6712653636932373, Discriminator Loss : 0.5023708939552307\n",
            "Epoch [166 / 200], Step [400 / 469], Generator Loss : 2.0336244106292725, Discriminator Loss : 0.35852372646331787\n",
            "Epoch [167 / 200], Step [100 / 469], Generator Loss : 3.2527079582214355, Discriminator Loss : 0.26424190402030945\n",
            "Epoch [167 / 200], Step [200 / 469], Generator Loss : 3.7954158782958984, Discriminator Loss : 0.49631375074386597\n",
            "Epoch [167 / 200], Step [300 / 469], Generator Loss : 4.277019500732422, Discriminator Loss : 0.8383857011795044\n",
            "Epoch [167 / 200], Step [400 / 469], Generator Loss : 3.091970920562744, Discriminator Loss : 0.3979406952857971\n",
            "Epoch [168 / 200], Step [100 / 469], Generator Loss : 5.181973457336426, Discriminator Loss : 0.6252139210700989\n",
            "Epoch [168 / 200], Step [200 / 469], Generator Loss : 2.636014938354492, Discriminator Loss : 0.48259174823760986\n",
            "Epoch [168 / 200], Step [300 / 469], Generator Loss : 3.161175012588501, Discriminator Loss : 0.382782906293869\n",
            "Epoch [168 / 200], Step [400 / 469], Generator Loss : 3.685507297515869, Discriminator Loss : 0.44143450260162354\n",
            "Epoch [169 / 200], Step [100 / 469], Generator Loss : 2.944199800491333, Discriminator Loss : 0.2211454063653946\n",
            "Epoch [169 / 200], Step [200 / 469], Generator Loss : 2.0101356506347656, Discriminator Loss : 0.3036344349384308\n",
            "Epoch [169 / 200], Step [300 / 469], Generator Loss : 1.9687668085098267, Discriminator Loss : 0.39811140298843384\n",
            "Epoch [169 / 200], Step [400 / 469], Generator Loss : 2.3896000385284424, Discriminator Loss : 0.34445691108703613\n",
            "Epoch [170 / 200], Step [100 / 469], Generator Loss : 2.8772807121276855, Discriminator Loss : 0.2312672734260559\n",
            "Epoch [170 / 200], Step [200 / 469], Generator Loss : 7.199412822723389, Discriminator Loss : 0.6983712315559387\n",
            "Epoch [170 / 200], Step [300 / 469], Generator Loss : 1.7539048194885254, Discriminator Loss : 0.539264440536499\n",
            "Epoch [170 / 200], Step [400 / 469], Generator Loss : 4.632682800292969, Discriminator Loss : 0.4643121063709259\n",
            "Epoch [171 / 200], Step [100 / 469], Generator Loss : 3.1306023597717285, Discriminator Loss : 0.38986721634864807\n",
            "Epoch [171 / 200], Step [200 / 469], Generator Loss : 1.0440101623535156, Discriminator Loss : 1.3876113891601562\n",
            "Epoch [171 / 200], Step [300 / 469], Generator Loss : 3.9323806762695312, Discriminator Loss : 0.3385961353778839\n",
            "Epoch [171 / 200], Step [400 / 469], Generator Loss : 3.7354869842529297, Discriminator Loss : 0.273674875497818\n",
            "Epoch [172 / 200], Step [100 / 469], Generator Loss : 2.0411536693573, Discriminator Loss : 0.32394611835479736\n",
            "Epoch [172 / 200], Step [200 / 469], Generator Loss : 3.639091968536377, Discriminator Loss : 0.20602619647979736\n",
            "Epoch [172 / 200], Step [300 / 469], Generator Loss : 2.9863622188568115, Discriminator Loss : 0.25850746035575867\n",
            "Epoch [172 / 200], Step [400 / 469], Generator Loss : 3.809823989868164, Discriminator Loss : 0.1902906596660614\n",
            "Epoch [173 / 200], Step [100 / 469], Generator Loss : 3.3316211700439453, Discriminator Loss : 0.26398804783821106\n",
            "Epoch [173 / 200], Step [200 / 469], Generator Loss : 2.019601345062256, Discriminator Loss : 0.3241143822669983\n",
            "Epoch [173 / 200], Step [300 / 469], Generator Loss : 2.421984910964966, Discriminator Loss : 0.44206058979034424\n",
            "Epoch [173 / 200], Step [400 / 469], Generator Loss : 3.3525705337524414, Discriminator Loss : 0.35984018445014954\n",
            "Epoch [174 / 200], Step [100 / 469], Generator Loss : 2.8479835987091064, Discriminator Loss : 0.31081411242485046\n",
            "Epoch [174 / 200], Step [200 / 469], Generator Loss : 3.0140843391418457, Discriminator Loss : 0.22345581650733948\n",
            "Epoch [174 / 200], Step [300 / 469], Generator Loss : 3.056385040283203, Discriminator Loss : 0.3106905221939087\n",
            "Epoch [174 / 200], Step [400 / 469], Generator Loss : 3.315974235534668, Discriminator Loss : 0.14520815014839172\n",
            "Epoch [175 / 200], Step [100 / 469], Generator Loss : 1.418540596961975, Discriminator Loss : 0.5760374665260315\n",
            "Epoch [175 / 200], Step [200 / 469], Generator Loss : 3.040958881378174, Discriminator Loss : 0.2064758986234665\n",
            "Epoch [175 / 200], Step [300 / 469], Generator Loss : 3.0071144104003906, Discriminator Loss : 0.3159335255622864\n",
            "Epoch [175 / 200], Step [400 / 469], Generator Loss : 2.2201876640319824, Discriminator Loss : 0.2008211463689804\n",
            "Epoch [176 / 200], Step [100 / 469], Generator Loss : 6.3789777755737305, Discriminator Loss : 0.40040719509124756\n",
            "Epoch [176 / 200], Step [200 / 469], Generator Loss : 4.3215742111206055, Discriminator Loss : 0.48743030428886414\n",
            "Epoch [176 / 200], Step [300 / 469], Generator Loss : 5.783773422241211, Discriminator Loss : 0.6892728209495544\n",
            "Epoch [176 / 200], Step [400 / 469], Generator Loss : 2.425142765045166, Discriminator Loss : 0.21282345056533813\n",
            "Epoch [177 / 200], Step [100 / 469], Generator Loss : 3.892578363418579, Discriminator Loss : 0.3948304057121277\n",
            "Epoch [177 / 200], Step [200 / 469], Generator Loss : 6.830289363861084, Discriminator Loss : 1.1768845319747925\n",
            "Epoch [177 / 200], Step [300 / 469], Generator Loss : 3.2820253372192383, Discriminator Loss : 0.33145394921302795\n",
            "Epoch [177 / 200], Step [400 / 469], Generator Loss : 1.8539605140686035, Discriminator Loss : 0.3195757269859314\n",
            "Epoch [178 / 200], Step [100 / 469], Generator Loss : 3.970515012741089, Discriminator Loss : 0.3210420608520508\n",
            "Epoch [178 / 200], Step [200 / 469], Generator Loss : 4.526853084564209, Discriminator Loss : 0.39922282099723816\n",
            "Epoch [178 / 200], Step [300 / 469], Generator Loss : 1.341424584388733, Discriminator Loss : 0.6548914909362793\n",
            "Epoch [178 / 200], Step [400 / 469], Generator Loss : 2.9650583267211914, Discriminator Loss : 0.23466694355010986\n",
            "Epoch [179 / 200], Step [100 / 469], Generator Loss : 2.548365592956543, Discriminator Loss : 0.23479607701301575\n",
            "Epoch [179 / 200], Step [200 / 469], Generator Loss : 2.930917739868164, Discriminator Loss : 0.2621890902519226\n",
            "Epoch [179 / 200], Step [300 / 469], Generator Loss : 1.9455444812774658, Discriminator Loss : 0.38337624073028564\n",
            "Epoch [179 / 200], Step [400 / 469], Generator Loss : 3.042072296142578, Discriminator Loss : 0.3306465744972229\n",
            "Epoch [180 / 200], Step [100 / 469], Generator Loss : 3.0658397674560547, Discriminator Loss : 0.27810215950012207\n",
            "Epoch [180 / 200], Step [200 / 469], Generator Loss : 4.083254814147949, Discriminator Loss : 0.391613632440567\n",
            "Epoch [180 / 200], Step [300 / 469], Generator Loss : 3.1848998069763184, Discriminator Loss : 0.09188878536224365\n",
            "Epoch [180 / 200], Step [400 / 469], Generator Loss : 3.664449691772461, Discriminator Loss : 0.4813508689403534\n",
            "Epoch [181 / 200], Step [100 / 469], Generator Loss : 2.56813907623291, Discriminator Loss : 0.29743069410324097\n",
            "Epoch [181 / 200], Step [200 / 469], Generator Loss : 2.675325393676758, Discriminator Loss : 0.3385521173477173\n",
            "Epoch [181 / 200], Step [300 / 469], Generator Loss : 3.7638721466064453, Discriminator Loss : 0.4033356308937073\n",
            "Epoch [181 / 200], Step [400 / 469], Generator Loss : 2.514566421508789, Discriminator Loss : 0.24500401318073273\n",
            "Epoch [182 / 200], Step [100 / 469], Generator Loss : 1.8891764879226685, Discriminator Loss : 0.3518064022064209\n",
            "Epoch [182 / 200], Step [200 / 469], Generator Loss : 3.2077388763427734, Discriminator Loss : 0.28402847051620483\n",
            "Epoch [182 / 200], Step [300 / 469], Generator Loss : 4.468224048614502, Discriminator Loss : 0.3593901991844177\n",
            "Epoch [182 / 200], Step [400 / 469], Generator Loss : 3.2858052253723145, Discriminator Loss : 0.20665839314460754\n",
            "Epoch [183 / 200], Step [100 / 469], Generator Loss : 2.2035062313079834, Discriminator Loss : 0.5290061831474304\n",
            "Epoch [183 / 200], Step [200 / 469], Generator Loss : 6.0369462966918945, Discriminator Loss : 0.7542807459831238\n",
            "Epoch [183 / 200], Step [300 / 469], Generator Loss : 3.1148123741149902, Discriminator Loss : 0.33970144391059875\n",
            "Epoch [183 / 200], Step [400 / 469], Generator Loss : 3.6203956604003906, Discriminator Loss : 0.3720970153808594\n",
            "Epoch [184 / 200], Step [100 / 469], Generator Loss : 3.608438491821289, Discriminator Loss : 0.46656283736228943\n",
            "Epoch [184 / 200], Step [200 / 469], Generator Loss : 1.5594666004180908, Discriminator Loss : 0.563512921333313\n",
            "Epoch [184 / 200], Step [300 / 469], Generator Loss : 2.006948709487915, Discriminator Loss : 0.3562943637371063\n",
            "Epoch [184 / 200], Step [400 / 469], Generator Loss : 1.6169650554656982, Discriminator Loss : 0.38954243063926697\n",
            "Epoch [185 / 200], Step [100 / 469], Generator Loss : 2.573880195617676, Discriminator Loss : 0.26369789242744446\n",
            "Epoch [185 / 200], Step [200 / 469], Generator Loss : 3.786818027496338, Discriminator Loss : 0.33404967188835144\n",
            "Epoch [185 / 200], Step [300 / 469], Generator Loss : 2.7019057273864746, Discriminator Loss : 0.3210285007953644\n",
            "Epoch [185 / 200], Step [400 / 469], Generator Loss : 2.8485732078552246, Discriminator Loss : 0.3880808353424072\n",
            "Epoch [186 / 200], Step [100 / 469], Generator Loss : 4.617938995361328, Discriminator Loss : 0.5423617362976074\n",
            "Epoch [186 / 200], Step [200 / 469], Generator Loss : 3.404967784881592, Discriminator Loss : 0.2199750542640686\n",
            "Epoch [186 / 200], Step [300 / 469], Generator Loss : 3.051267147064209, Discriminator Loss : 0.30188190937042236\n",
            "Epoch [186 / 200], Step [400 / 469], Generator Loss : 6.7363433837890625, Discriminator Loss : 0.4509645998477936\n",
            "Epoch [187 / 200], Step [100 / 469], Generator Loss : 1.7005687952041626, Discriminator Loss : 0.5124521255493164\n",
            "Epoch [187 / 200], Step [200 / 469], Generator Loss : 3.6830692291259766, Discriminator Loss : 0.250772625207901\n",
            "Epoch [187 / 200], Step [300 / 469], Generator Loss : 3.090108871459961, Discriminator Loss : 0.3630427122116089\n",
            "Epoch [187 / 200], Step [400 / 469], Generator Loss : 2.9869115352630615, Discriminator Loss : 0.38262084126472473\n",
            "Epoch [188 / 200], Step [100 / 469], Generator Loss : 2.3217415809631348, Discriminator Loss : 0.43729814887046814\n",
            "Epoch [188 / 200], Step [200 / 469], Generator Loss : 3.2425756454467773, Discriminator Loss : 0.209818497300148\n",
            "Epoch [188 / 200], Step [300 / 469], Generator Loss : 3.2394304275512695, Discriminator Loss : 0.2221364974975586\n",
            "Epoch [188 / 200], Step [400 / 469], Generator Loss : 3.6476778984069824, Discriminator Loss : 0.5183593034744263\n",
            "Epoch [189 / 200], Step [100 / 469], Generator Loss : 2.6933884620666504, Discriminator Loss : 0.3097567558288574\n",
            "Epoch [189 / 200], Step [200 / 469], Generator Loss : 3.1389927864074707, Discriminator Loss : 0.13963955640792847\n",
            "Epoch [189 / 200], Step [300 / 469], Generator Loss : 2.294041633605957, Discriminator Loss : 0.2753911018371582\n",
            "Epoch [189 / 200], Step [400 / 469], Generator Loss : 3.3355846405029297, Discriminator Loss : 0.315158486366272\n",
            "Epoch [190 / 200], Step [100 / 469], Generator Loss : 3.481858491897583, Discriminator Loss : 0.28631433844566345\n",
            "Epoch [190 / 200], Step [200 / 469], Generator Loss : 3.178133964538574, Discriminator Loss : 0.2048797309398651\n",
            "Epoch [190 / 200], Step [300 / 469], Generator Loss : 2.543562650680542, Discriminator Loss : 0.35130634903907776\n",
            "Epoch [190 / 200], Step [400 / 469], Generator Loss : 2.997870445251465, Discriminator Loss : 0.21903890371322632\n",
            "Epoch [191 / 200], Step [100 / 469], Generator Loss : 2.3748838901519775, Discriminator Loss : 0.40843379497528076\n",
            "Epoch [191 / 200], Step [200 / 469], Generator Loss : 3.38022518157959, Discriminator Loss : 0.2214813530445099\n",
            "Epoch [191 / 200], Step [300 / 469], Generator Loss : 3.6485280990600586, Discriminator Loss : 0.24497808516025543\n",
            "Epoch [191 / 200], Step [400 / 469], Generator Loss : 2.30631422996521, Discriminator Loss : 0.42779725790023804\n",
            "Epoch [192 / 200], Step [100 / 469], Generator Loss : 2.5677430629730225, Discriminator Loss : 0.21777305006980896\n",
            "Epoch [192 / 200], Step [200 / 469], Generator Loss : 5.123271942138672, Discriminator Loss : 0.4646666944026947\n",
            "Epoch [192 / 200], Step [300 / 469], Generator Loss : 4.309457302093506, Discriminator Loss : 0.727304220199585\n",
            "Epoch [192 / 200], Step [400 / 469], Generator Loss : 3.3660805225372314, Discriminator Loss : 0.23190838098526\n",
            "Epoch [193 / 200], Step [100 / 469], Generator Loss : 4.377782821655273, Discriminator Loss : 0.3514834940433502\n",
            "Epoch [193 / 200], Step [200 / 469], Generator Loss : 3.3360421657562256, Discriminator Loss : 0.3558095097541809\n",
            "Epoch [193 / 200], Step [300 / 469], Generator Loss : 3.6522092819213867, Discriminator Loss : 0.26946210861206055\n",
            "Epoch [193 / 200], Step [400 / 469], Generator Loss : 2.3503096103668213, Discriminator Loss : 0.3879009485244751\n",
            "Epoch [194 / 200], Step [100 / 469], Generator Loss : 3.517434597015381, Discriminator Loss : 0.1371096670627594\n",
            "Epoch [194 / 200], Step [200 / 469], Generator Loss : 2.435969829559326, Discriminator Loss : 0.28970909118652344\n",
            "Epoch [194 / 200], Step [300 / 469], Generator Loss : 2.723116397857666, Discriminator Loss : 0.2697712779045105\n",
            "Epoch [194 / 200], Step [400 / 469], Generator Loss : 2.0175299644470215, Discriminator Loss : 0.5498658418655396\n",
            "Epoch [195 / 200], Step [100 / 469], Generator Loss : 2.552608013153076, Discriminator Loss : 0.37438538670539856\n",
            "Epoch [195 / 200], Step [200 / 469], Generator Loss : 4.496072292327881, Discriminator Loss : 0.6394628286361694\n",
            "Epoch [195 / 200], Step [300 / 469], Generator Loss : 2.554312229156494, Discriminator Loss : 0.4099695682525635\n",
            "Epoch [195 / 200], Step [400 / 469], Generator Loss : 3.0003514289855957, Discriminator Loss : 0.4509296417236328\n",
            "Epoch [196 / 200], Step [100 / 469], Generator Loss : 3.204223155975342, Discriminator Loss : 0.48252320289611816\n",
            "Epoch [196 / 200], Step [200 / 469], Generator Loss : 2.878389835357666, Discriminator Loss : 0.20061497390270233\n",
            "Epoch [196 / 200], Step [300 / 469], Generator Loss : 2.809295177459717, Discriminator Loss : 0.3324987292289734\n",
            "Epoch [196 / 200], Step [400 / 469], Generator Loss : 2.4861011505126953, Discriminator Loss : 0.2856018543243408\n",
            "Epoch [197 / 200], Step [100 / 469], Generator Loss : 3.4847967624664307, Discriminator Loss : 0.2513856887817383\n",
            "Epoch [197 / 200], Step [200 / 469], Generator Loss : 2.333421230316162, Discriminator Loss : 0.3308637738227844\n",
            "Epoch [197 / 200], Step [300 / 469], Generator Loss : 2.863466739654541, Discriminator Loss : 0.43474191427230835\n",
            "Epoch [197 / 200], Step [400 / 469], Generator Loss : 3.167417049407959, Discriminator Loss : 0.3258945941925049\n",
            "Epoch [198 / 200], Step [100 / 469], Generator Loss : 3.0694403648376465, Discriminator Loss : 0.27126097679138184\n",
            "Epoch [198 / 200], Step [200 / 469], Generator Loss : 2.891645669937134, Discriminator Loss : 0.31666672229766846\n",
            "Epoch [198 / 200], Step [300 / 469], Generator Loss : 2.8513565063476562, Discriminator Loss : 0.2451416552066803\n",
            "Epoch [198 / 200], Step [400 / 469], Generator Loss : 3.551063299179077, Discriminator Loss : 0.26969635486602783\n",
            "Epoch [199 / 200], Step [100 / 469], Generator Loss : 3.242534637451172, Discriminator Loss : 0.1901620328426361\n",
            "Epoch [199 / 200], Step [200 / 469], Generator Loss : 2.227370262145996, Discriminator Loss : 0.31767183542251587\n",
            "Epoch [199 / 200], Step [300 / 469], Generator Loss : 2.250741481781006, Discriminator Loss : 0.586477518081665\n",
            "Epoch [199 / 200], Step [400 / 469], Generator Loss : 1.9575010538101196, Discriminator Loss : 0.3718995153903961\n",
            "Epoch [200 / 200], Step [100 / 469], Generator Loss : 5.463912010192871, Discriminator Loss : 0.5422064065933228\n",
            "Epoch [200 / 200], Step [200 / 469], Generator Loss : 2.243901014328003, Discriminator Loss : 0.4028339385986328\n",
            "Epoch [200 / 200], Step [300 / 469], Generator Loss : 3.5073394775390625, Discriminator Loss : 0.26676154136657715\n",
            "Epoch [200 / 200], Step [400 / 469], Generator Loss : 3.14141845703125, Discriminator Loss : 0.2732980251312256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(\"10000.png\")"
      ],
      "metadata": {
        "id": "Rpc_sPevTPpy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "ec339909-fed9-46da-d8e0-dc59de570436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image(\"90000.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "vEwfh0w0cbZu",
        "outputId": "55f7c4c6-b1b6-4db1-89de-b34651000666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lTK2tB7iqhj0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}